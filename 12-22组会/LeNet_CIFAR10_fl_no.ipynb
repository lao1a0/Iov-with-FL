{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-69HIntBbECK"
   },
   "source": [
    "# 参数配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QttTX-t8bECP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "a5KEY2OFbECV"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EcWUwShObECX"
   },
   "outputs": [],
   "source": [
    "# transforms\n",
    "train_transforms = transforms.Compose([#transforms.RandomRotation(30),\n",
    "                                       # transforms.RandomResizedCrop(224),\n",
    "                                       # transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.5,], [0.5,])]) # mean, std\n",
    "\n",
    "\n",
    "test_transforms = transforms.Compose([#transforms.Resize(255),\n",
    "                                      #transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.5,], [0.5,])]) # mean, std\n",
    "\n",
    "\n",
    "# choose the training and test datasets\n",
    "\n",
    "# federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader\n",
    "#     datasets.CIFAR100('/home/zhaojia-raoxy/data', train=True, download=True,\n",
    "#                    transform=train_transforms)\n",
    "#     .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "#     batch_size=20, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "# federated_test_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader\n",
    "#     datasets.CIFAR100('/home/zhaojia-raoxy/data', train=False, download=True,\n",
    "#                    transform=test_transforms)\n",
    "#     .federate((secure_worker_a, secure_worker_b)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "#     batch_size=20, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "YjjZeX-ObECY",
    "outputId": "40dbff2a-a5ce-4605-eef0-33841fe1701a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "federated_train_loader = torch.utils.data.DataLoader( # <-- this is now a FederatedDataLoader\n",
    "    datasets.CIFAR10('/home/zhaojia-raoxy/data', train=True, download=True,\n",
    "                   transform=train_transforms), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "    batch_size=200, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "federated_test_loader = torch.utils.data.DataLoader( # <-- this is now a FederatedDataLoader\n",
    "    datasets.CIFAR10('/home/zhaojia-raoxy/data', train=False, download=True,\n",
    "                   transform=test_transforms), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "    batch_size=200, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQoXtD4vbECa"
   },
   "source": [
    "# LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "U04vxz6rbECc"
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, channel=3, hideen=768, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        act = nn.Sigmoid\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channel, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=1),\n",
    "            act(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hideen, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = LeNet(channel=3, hideen=768, num_classes=10).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.03) # TODO momentum is not supported at the moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWf3ovNfbECc"
   },
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "L1Pd0cIibECd"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pA7Ezx4DbECe"
   },
   "outputs": [],
   "source": [
    "loss_test=[]\n",
    "acc_test=[]\n",
    "def test(model, device, federated_test_loader, batch_size):\n",
    "    global criterion,txt,loss_test,acc_test\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    n=0\n",
    "    with torch.no_grad():\n",
    "        for data, target in federated_test_loader:\n",
    "#             model.send(data.location) # <-- NEW: send the model in virtual workers to Trusted Aggregator\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            n += target.shape[0]\n",
    "            loss = criterion(output, target.long())\n",
    "#             loss = F.nll_loss(output, target, reduction='sum')\n",
    "#             model.get()\n",
    "#             test_loss += loss.get() # sum up batch loss\n",
    "            test_loss += loss.item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            # print(\"{}\\t{}\".format(correct,target.shape))\n",
    "\n",
    "    test_loss /= len(federated_test_loader)\n",
    "    loss_test.append(test_loss)\n",
    "    acc_test.append(correct*1.0/n)\n",
    "\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        test_loss, correct, len(federated_test_loader) * batch_size,\n",
    "        100. * correct / n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [],
    "id": "zijuCXWRbECf"
   },
   "outputs": [],
   "source": [
    "loss_train=[]\n",
    "acc_train=[]\n",
    "def train(model, device, federated_train_loader, optimizer, epoch, batch_size):\n",
    "    global criterion,txt,loss_train,acc_train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    n=0\n",
    "    for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
    "#         model.send(data.location) # <-- NEW: send the model to the right location\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        n += target.shape[0]\n",
    "        loss = criterion(output, target.long())\n",
    "#         loss = F.cross_entropy(output, target.long())\n",
    "#         loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         model.get() # <-- NEW: get the model back\n",
    "        pred = output.argmax(1, keepdim=True) # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        # print(\"{}\\t{}\".format(correct,target.shape))\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "    train_loss /= len(federated_train_loader)\n",
    "    loss_train.append(train_loss)\n",
    "    acc_train.append(correct*1.0/ n)\n",
    "\n",
    "    print('Train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "    train_loss, correct, len(federated_train_loader) * batch_size,\n",
    "     100.*correct / n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3wgs-_42bECf",
    "outputId": "302b768c-dee8-4391-cc3d-754fa2b55e4a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Average loss: 2.3108, Accuracy: 5052/50000 (10%)\n",
      "Test set: Average loss: 2.3074, Accuracy: 1000/10000 (10%)\n",
      "Train set: Average loss: 2.3089, Accuracy: 5099/50000 (10%)\n",
      "Test set: Average loss: 2.3079, Accuracy: 1000/10000 (10%)\n",
      "Train set: Average loss: 2.3080, Accuracy: 4959/50000 (10%)\n",
      "Test set: Average loss: 2.3068, Accuracy: 1000/10000 (10%)\n",
      "Train set: Average loss: 2.3065, Accuracy: 5020/50000 (10%)\n",
      "Test set: Average loss: 2.3068, Accuracy: 1007/10000 (10%)\n",
      "Train set: Average loss: 2.3054, Accuracy: 4974/50000 (10%)\n",
      "Test set: Average loss: 2.3051, Accuracy: 1000/10000 (10%)\n",
      "Train set: Average loss: 2.3046, Accuracy: 5012/50000 (10%)\n",
      "Test set: Average loss: 2.3032, Accuracy: 1009/10000 (10%)\n",
      "Train set: Average loss: 2.3039, Accuracy: 5032/50000 (10%)\n",
      "Test set: Average loss: 2.3024, Accuracy: 982/10000 (10%)\n",
      "Train set: Average loss: 2.3023, Accuracy: 5216/50000 (10%)\n",
      "Test set: Average loss: 2.3021, Accuracy: 1000/10000 (10%)\n",
      "Train set: Average loss: 2.2990, Accuracy: 5854/50000 (12%)\n",
      "Test set: Average loss: 2.2965, Accuracy: 1121/10000 (11%)\n",
      "Train set: Average loss: 2.2837, Accuracy: 7271/50000 (15%)\n",
      "Test set: Average loss: 2.2579, Accuracy: 1951/10000 (20%)\n",
      "Train set: Average loss: 2.1892, Accuracy: 10534/50000 (21%)\n",
      "Test set: Average loss: 2.1160, Accuracy: 2295/10000 (23%)\n",
      "Train set: Average loss: 2.0910, Accuracy: 12055/50000 (24%)\n",
      "Test set: Average loss: 2.0524, Accuracy: 2600/10000 (26%)\n",
      "Train set: Average loss: 2.0489, Accuracy: 12720/50000 (25%)\n",
      "Test set: Average loss: 2.0211, Accuracy: 2682/10000 (27%)\n",
      "Train set: Average loss: 2.0266, Accuracy: 12988/50000 (26%)\n",
      "Test set: Average loss: 2.0057, Accuracy: 2697/10000 (27%)\n",
      "Train set: Average loss: 2.0135, Accuracy: 13280/50000 (27%)\n",
      "Test set: Average loss: 1.9965, Accuracy: 2716/10000 (27%)\n",
      "Train set: Average loss: 2.0035, Accuracy: 13464/50000 (27%)\n",
      "Test set: Average loss: 1.9888, Accuracy: 2725/10000 (27%)\n",
      "Train set: Average loss: 1.9927, Accuracy: 13695/50000 (27%)\n",
      "Test set: Average loss: 1.9773, Accuracy: 2806/10000 (28%)\n",
      "Train set: Average loss: 1.9811, Accuracy: 13919/50000 (28%)\n",
      "Test set: Average loss: 1.9646, Accuracy: 2913/10000 (29%)\n",
      "Train set: Average loss: 1.9678, Accuracy: 14254/50000 (29%)\n",
      "Test set: Average loss: 1.9500, Accuracy: 2970/10000 (30%)\n",
      "Train set: Average loss: 1.9542, Accuracy: 14751/50000 (30%)\n",
      "Test set: Average loss: 1.9361, Accuracy: 3065/10000 (31%)\n",
      "Train set: Average loss: 1.9381, Accuracy: 15084/50000 (30%)\n",
      "Test set: Average loss: 1.9237, Accuracy: 2994/10000 (30%)\n",
      "Train set: Average loss: 1.9233, Accuracy: 15310/50000 (31%)\n",
      "Test set: Average loss: 1.9103, Accuracy: 3168/10000 (32%)\n",
      "Train set: Average loss: 1.9091, Accuracy: 15735/50000 (31%)\n",
      "Test set: Average loss: 1.8944, Accuracy: 3180/10000 (32%)\n",
      "Train set: Average loss: 1.8947, Accuracy: 16123/50000 (32%)\n",
      "Test set: Average loss: 1.8791, Accuracy: 3383/10000 (34%)\n",
      "Train set: Average loss: 1.8808, Accuracy: 16410/50000 (33%)\n",
      "Test set: Average loss: 1.8660, Accuracy: 3436/10000 (34%)\n",
      "Train set: Average loss: 1.8671, Accuracy: 16666/50000 (33%)\n",
      "Test set: Average loss: 1.8522, Accuracy: 3464/10000 (35%)\n",
      "Train set: Average loss: 1.8520, Accuracy: 17090/50000 (34%)\n",
      "Test set: Average loss: 1.8417, Accuracy: 3485/10000 (35%)\n",
      "Train set: Average loss: 1.8378, Accuracy: 17247/50000 (34%)\n",
      "Test set: Average loss: 1.8220, Accuracy: 3581/10000 (36%)\n",
      "Train set: Average loss: 1.8234, Accuracy: 17636/50000 (35%)\n",
      "Test set: Average loss: 1.8098, Accuracy: 3645/10000 (36%)\n",
      "Train set: Average loss: 1.8096, Accuracy: 17854/50000 (36%)\n",
      "Test set: Average loss: 1.7926, Accuracy: 3712/10000 (37%)\n",
      "Train set: Average loss: 1.7965, Accuracy: 18116/50000 (36%)\n",
      "Test set: Average loss: 1.7780, Accuracy: 3757/10000 (38%)\n",
      "Train set: Average loss: 1.7839, Accuracy: 18331/50000 (37%)\n",
      "Test set: Average loss: 1.7688, Accuracy: 3734/10000 (37%)\n",
      "Train set: Average loss: 1.7720, Accuracy: 18582/50000 (37%)\n",
      "Test set: Average loss: 1.7598, Accuracy: 3793/10000 (38%)\n",
      "Train set: Average loss: 1.7605, Accuracy: 18783/50000 (38%)\n",
      "Test set: Average loss: 1.7429, Accuracy: 3864/10000 (39%)\n",
      "Train set: Average loss: 1.7497, Accuracy: 18989/50000 (38%)\n",
      "Test set: Average loss: 1.7338, Accuracy: 3903/10000 (39%)\n",
      "Train set: Average loss: 1.7383, Accuracy: 19220/50000 (38%)\n",
      "Test set: Average loss: 1.7207, Accuracy: 3901/10000 (39%)\n",
      "Train set: Average loss: 1.7271, Accuracy: 19501/50000 (39%)\n",
      "Test set: Average loss: 1.7127, Accuracy: 3957/10000 (40%)\n",
      "Train set: Average loss: 1.7160, Accuracy: 19645/50000 (39%)\n",
      "Test set: Average loss: 1.7050, Accuracy: 3946/10000 (39%)\n",
      "Train set: Average loss: 1.7055, Accuracy: 19887/50000 (40%)\n",
      "Test set: Average loss: 1.6877, Accuracy: 4018/10000 (40%)\n",
      "Train set: Average loss: 1.6939, Accuracy: 19969/50000 (40%)\n",
      "Test set: Average loss: 1.6784, Accuracy: 4062/10000 (41%)\n",
      "Train set: Average loss: 1.6832, Accuracy: 20162/50000 (40%)\n",
      "Test set: Average loss: 1.6665, Accuracy: 4114/10000 (41%)\n",
      "Train set: Average loss: 1.6733, Accuracy: 20329/50000 (41%)\n",
      "Test set: Average loss: 1.6551, Accuracy: 4095/10000 (41%)\n",
      "Train set: Average loss: 1.6640, Accuracy: 20534/50000 (41%)\n",
      "Test set: Average loss: 1.6455, Accuracy: 4164/10000 (42%)\n",
      "Train set: Average loss: 1.6545, Accuracy: 20610/50000 (41%)\n",
      "Test set: Average loss: 1.6386, Accuracy: 4192/10000 (42%)\n",
      "Train set: Average loss: 1.6459, Accuracy: 20806/50000 (42%)\n",
      "Test set: Average loss: 1.6356, Accuracy: 4192/10000 (42%)\n",
      "Train set: Average loss: 1.6374, Accuracy: 20955/50000 (42%)\n",
      "Test set: Average loss: 1.6244, Accuracy: 4271/10000 (43%)\n",
      "Train set: Average loss: 1.6295, Accuracy: 21040/50000 (42%)\n",
      "Test set: Average loss: 1.6134, Accuracy: 4287/10000 (43%)\n",
      "Train set: Average loss: 1.6223, Accuracy: 21193/50000 (42%)\n",
      "Test set: Average loss: 1.6043, Accuracy: 4320/10000 (43%)\n",
      "Train set: Average loss: 1.6151, Accuracy: 21283/50000 (43%)\n",
      "Test set: Average loss: 1.6013, Accuracy: 4322/10000 (43%)\n",
      "Train set: Average loss: 1.6082, Accuracy: 21462/50000 (43%)\n",
      "Test set: Average loss: 1.5930, Accuracy: 4370/10000 (44%)\n",
      "Train set: Average loss: 1.6015, Accuracy: 21643/50000 (43%)\n",
      "Test set: Average loss: 1.5860, Accuracy: 4353/10000 (44%)\n",
      "Train set: Average loss: 1.5954, Accuracy: 21766/50000 (44%)\n",
      "Test set: Average loss: 1.5838, Accuracy: 4391/10000 (44%)\n",
      "Train set: Average loss: 1.5895, Accuracy: 21874/50000 (44%)\n",
      "Test set: Average loss: 1.5753, Accuracy: 4420/10000 (44%)\n",
      "Train set: Average loss: 1.5844, Accuracy: 21834/50000 (44%)\n",
      "Test set: Average loss: 1.5701, Accuracy: 4437/10000 (44%)\n",
      "Train set: Average loss: 1.5774, Accuracy: 22105/50000 (44%)\n",
      "Test set: Average loss: 1.5640, Accuracy: 4486/10000 (45%)\n",
      "Train set: Average loss: 1.5715, Accuracy: 22160/50000 (44%)\n",
      "Test set: Average loss: 1.5623, Accuracy: 4484/10000 (45%)\n",
      "Train set: Average loss: 1.5664, Accuracy: 22236/50000 (44%)\n",
      "Test set: Average loss: 1.5528, Accuracy: 4475/10000 (45%)\n",
      "Train set: Average loss: 1.5613, Accuracy: 22327/50000 (45%)\n",
      "Test set: Average loss: 1.5625, Accuracy: 4463/10000 (45%)\n",
      "Train set: Average loss: 1.5562, Accuracy: 22475/50000 (45%)\n",
      "Test set: Average loss: 1.5440, Accuracy: 4526/10000 (45%)\n",
      "Train set: Average loss: 1.5509, Accuracy: 22508/50000 (45%)\n",
      "Test set: Average loss: 1.5441, Accuracy: 4525/10000 (45%)\n",
      "Train set: Average loss: 1.5468, Accuracy: 22606/50000 (45%)\n",
      "Test set: Average loss: 1.5407, Accuracy: 4555/10000 (46%)\n",
      "Train set: Average loss: 1.5424, Accuracy: 22684/50000 (45%)\n",
      "Test set: Average loss: 1.5336, Accuracy: 4582/10000 (46%)\n",
      "Train set: Average loss: 1.5371, Accuracy: 22791/50000 (46%)\n",
      "Test set: Average loss: 1.5264, Accuracy: 4608/10000 (46%)\n",
      "Train set: Average loss: 1.5326, Accuracy: 22932/50000 (46%)\n",
      "Test set: Average loss: 1.5362, Accuracy: 4538/10000 (45%)\n",
      "Train set: Average loss: 1.5283, Accuracy: 22982/50000 (46%)\n",
      "Test set: Average loss: 1.5218, Accuracy: 4555/10000 (46%)\n",
      "Train set: Average loss: 1.5243, Accuracy: 23046/50000 (46%)\n",
      "Test set: Average loss: 1.5171, Accuracy: 4614/10000 (46%)\n",
      "Train set: Average loss: 1.5191, Accuracy: 23087/50000 (46%)\n",
      "Test set: Average loss: 1.5110, Accuracy: 4631/10000 (46%)\n",
      "Train set: Average loss: 1.5151, Accuracy: 23111/50000 (46%)\n",
      "Test set: Average loss: 1.5051, Accuracy: 4663/10000 (47%)\n",
      "Train set: Average loss: 1.5114, Accuracy: 23203/50000 (46%)\n",
      "Test set: Average loss: 1.5051, Accuracy: 4635/10000 (46%)\n",
      "Train set: Average loss: 1.5071, Accuracy: 23334/50000 (47%)\n",
      "Test set: Average loss: 1.5068, Accuracy: 4587/10000 (46%)\n",
      "Train set: Average loss: 1.5032, Accuracy: 23404/50000 (47%)\n",
      "Test set: Average loss: 1.5004, Accuracy: 4641/10000 (46%)\n",
      "Train set: Average loss: 1.4984, Accuracy: 23527/50000 (47%)\n",
      "Test set: Average loss: 1.4945, Accuracy: 4646/10000 (46%)\n",
      "Train set: Average loss: 1.4936, Accuracy: 23560/50000 (47%)\n",
      "Test set: Average loss: 1.4901, Accuracy: 4682/10000 (47%)\n",
      "Train set: Average loss: 1.4895, Accuracy: 23635/50000 (47%)\n",
      "Test set: Average loss: 1.4824, Accuracy: 4703/10000 (47%)\n",
      "Train set: Average loss: 1.4849, Accuracy: 23711/50000 (47%)\n",
      "Test set: Average loss: 1.4842, Accuracy: 4708/10000 (47%)\n",
      "Train set: Average loss: 1.4810, Accuracy: 23783/50000 (48%)\n",
      "Test set: Average loss: 1.4758, Accuracy: 4727/10000 (47%)\n",
      "Train set: Average loss: 1.4766, Accuracy: 23851/50000 (48%)\n",
      "Test set: Average loss: 1.4710, Accuracy: 4733/10000 (47%)\n",
      "Train set: Average loss: 1.4736, Accuracy: 23854/50000 (48%)\n",
      "Test set: Average loss: 1.4680, Accuracy: 4776/10000 (48%)\n",
      "Train set: Average loss: 1.4690, Accuracy: 23954/50000 (48%)\n",
      "Test set: Average loss: 1.4683, Accuracy: 4751/10000 (48%)\n",
      "Train set: Average loss: 1.4653, Accuracy: 24000/50000 (48%)\n",
      "Test set: Average loss: 1.4615, Accuracy: 4789/10000 (48%)\n",
      "Train set: Average loss: 1.4608, Accuracy: 24137/50000 (48%)\n",
      "Test set: Average loss: 1.4559, Accuracy: 4796/10000 (48%)\n",
      "Train set: Average loss: 1.4572, Accuracy: 24182/50000 (48%)\n",
      "Test set: Average loss: 1.4547, Accuracy: 4811/10000 (48%)\n",
      "Train set: Average loss: 1.4525, Accuracy: 24274/50000 (49%)\n",
      "Test set: Average loss: 1.4506, Accuracy: 4808/10000 (48%)\n",
      "Train set: Average loss: 1.4487, Accuracy: 24386/50000 (49%)\n",
      "Test set: Average loss: 1.4437, Accuracy: 4854/10000 (49%)\n",
      "Train set: Average loss: 1.4445, Accuracy: 24354/50000 (49%)\n",
      "Test set: Average loss: 1.4456, Accuracy: 4812/10000 (48%)\n",
      "Train set: Average loss: 1.4409, Accuracy: 24469/50000 (49%)\n",
      "Test set: Average loss: 1.4376, Accuracy: 4845/10000 (48%)\n",
      "Train set: Average loss: 1.4371, Accuracy: 24471/50000 (49%)\n",
      "Test set: Average loss: 1.4337, Accuracy: 4860/10000 (49%)\n",
      "Train set: Average loss: 1.4331, Accuracy: 24636/50000 (49%)\n",
      "Test set: Average loss: 1.4328, Accuracy: 4868/10000 (49%)\n",
      "Train set: Average loss: 1.4293, Accuracy: 24703/50000 (49%)\n",
      "Test set: Average loss: 1.4250, Accuracy: 4877/10000 (49%)\n",
      "Train set: Average loss: 1.4266, Accuracy: 24686/50000 (49%)\n",
      "Test set: Average loss: 1.4249, Accuracy: 4887/10000 (49%)\n",
      "Train set: Average loss: 1.4222, Accuracy: 24813/50000 (50%)\n",
      "Test set: Average loss: 1.4283, Accuracy: 4880/10000 (49%)\n",
      "Train set: Average loss: 1.4179, Accuracy: 24930/50000 (50%)\n",
      "Test set: Average loss: 1.4189, Accuracy: 4942/10000 (49%)\n",
      "Train set: Average loss: 1.4146, Accuracy: 24842/50000 (50%)\n",
      "Test set: Average loss: 1.4179, Accuracy: 4886/10000 (49%)\n",
      "Train set: Average loss: 1.4107, Accuracy: 24901/50000 (50%)\n",
      "Test set: Average loss: 1.4093, Accuracy: 4952/10000 (50%)\n",
      "Train set: Average loss: 1.4071, Accuracy: 25069/50000 (50%)\n",
      "Test set: Average loss: 1.4066, Accuracy: 4943/10000 (49%)\n",
      "Train set: Average loss: 1.4044, Accuracy: 25083/50000 (50%)\n",
      "Test set: Average loss: 1.4146, Accuracy: 4921/10000 (49%)\n",
      "Train set: Average loss: 1.4015, Accuracy: 25116/50000 (50%)\n",
      "Test set: Average loss: 1.4062, Accuracy: 4971/10000 (50%)\n",
      "Train set: Average loss: 1.3978, Accuracy: 25242/50000 (50%)\n",
      "Test set: Average loss: 1.3969, Accuracy: 4971/10000 (50%)\n",
      "Train set: Average loss: 1.3931, Accuracy: 25185/50000 (50%)\n",
      "Test set: Average loss: 1.3936, Accuracy: 4979/10000 (50%)\n",
      "Train set: Average loss: 1.3903, Accuracy: 25264/50000 (51%)\n",
      "Test set: Average loss: 1.4010, Accuracy: 4996/10000 (50%)\n",
      "Train set: Average loss: 1.3875, Accuracy: 25367/50000 (51%)\n",
      "Test set: Average loss: 1.3920, Accuracy: 5010/10000 (50%)\n",
      "Train set: Average loss: 1.3830, Accuracy: 25505/50000 (51%)\n",
      "Test set: Average loss: 1.3851, Accuracy: 5011/10000 (50%)\n",
      "Train set: Average loss: 1.3802, Accuracy: 25517/50000 (51%)\n",
      "Test set: Average loss: 1.3802, Accuracy: 5059/10000 (51%)\n",
      "Train set: Average loss: 1.3778, Accuracy: 25512/50000 (51%)\n",
      "Test set: Average loss: 1.3766, Accuracy: 5080/10000 (51%)\n",
      "Train set: Average loss: 1.3740, Accuracy: 25572/50000 (51%)\n",
      "Test set: Average loss: 1.3756, Accuracy: 5080/10000 (51%)\n",
      "Train set: Average loss: 1.3711, Accuracy: 25653/50000 (51%)\n",
      "Test set: Average loss: 1.3732, Accuracy: 5100/10000 (51%)\n",
      "Train set: Average loss: 1.3672, Accuracy: 25744/50000 (51%)\n",
      "Test set: Average loss: 1.3684, Accuracy: 5100/10000 (51%)\n",
      "Train set: Average loss: 1.3658, Accuracy: 25807/50000 (52%)\n",
      "Test set: Average loss: 1.3702, Accuracy: 5114/10000 (51%)\n",
      "Train set: Average loss: 1.3615, Accuracy: 25831/50000 (52%)\n",
      "Test set: Average loss: 1.3631, Accuracy: 5135/10000 (51%)\n",
      "Train set: Average loss: 1.3591, Accuracy: 25846/50000 (52%)\n",
      "Test set: Average loss: 1.3660, Accuracy: 5128/10000 (51%)\n",
      "Train set: Average loss: 1.3558, Accuracy: 25915/50000 (52%)\n",
      "Test set: Average loss: 1.3587, Accuracy: 5150/10000 (52%)\n",
      "Train set: Average loss: 1.3532, Accuracy: 25965/50000 (52%)\n",
      "Test set: Average loss: 1.3566, Accuracy: 5163/10000 (52%)\n",
      "Train set: Average loss: 1.3501, Accuracy: 26037/50000 (52%)\n",
      "Test set: Average loss: 1.3535, Accuracy: 5157/10000 (52%)\n",
      "Train set: Average loss: 1.3470, Accuracy: 26049/50000 (52%)\n",
      "Test set: Average loss: 1.3539, Accuracy: 5158/10000 (52%)\n",
      "Train set: Average loss: 1.3456, Accuracy: 26058/50000 (52%)\n",
      "Test set: Average loss: 1.3489, Accuracy: 5199/10000 (52%)\n",
      "Train set: Average loss: 1.3423, Accuracy: 26164/50000 (52%)\n",
      "Test set: Average loss: 1.3534, Accuracy: 5152/10000 (52%)\n",
      "Train set: Average loss: 1.3397, Accuracy: 26184/50000 (52%)\n",
      "Test set: Average loss: 1.3471, Accuracy: 5202/10000 (52%)\n",
      "Train set: Average loss: 1.3361, Accuracy: 26247/50000 (52%)\n",
      "Test set: Average loss: 1.3402, Accuracy: 5240/10000 (52%)\n",
      "Train set: Average loss: 1.3343, Accuracy: 26303/50000 (53%)\n",
      "Test set: Average loss: 1.3399, Accuracy: 5218/10000 (52%)\n",
      "Train set: Average loss: 1.3309, Accuracy: 26408/50000 (53%)\n",
      "Test set: Average loss: 1.3358, Accuracy: 5272/10000 (53%)\n",
      "Train set: Average loss: 1.3291, Accuracy: 26353/50000 (53%)\n",
      "Test set: Average loss: 1.3397, Accuracy: 5219/10000 (52%)\n",
      "Train set: Average loss: 1.3257, Accuracy: 26460/50000 (53%)\n",
      "Test set: Average loss: 1.3360, Accuracy: 5232/10000 (52%)\n",
      "Train set: Average loss: 1.3234, Accuracy: 26469/50000 (53%)\n",
      "Test set: Average loss: 1.3289, Accuracy: 5278/10000 (53%)\n",
      "Train set: Average loss: 1.3210, Accuracy: 26542/50000 (53%)\n",
      "Test set: Average loss: 1.3319, Accuracy: 5242/10000 (52%)\n",
      "Train set: Average loss: 1.3187, Accuracy: 26558/50000 (53%)\n",
      "Test set: Average loss: 1.3277, Accuracy: 5273/10000 (53%)\n",
      "Train set: Average loss: 1.3158, Accuracy: 26654/50000 (53%)\n",
      "Test set: Average loss: 1.3263, Accuracy: 5248/10000 (52%)\n",
      "Train set: Average loss: 1.3129, Accuracy: 26684/50000 (53%)\n",
      "Test set: Average loss: 1.3226, Accuracy: 5273/10000 (53%)\n",
      "Train set: Average loss: 1.3111, Accuracy: 26766/50000 (54%)\n",
      "Test set: Average loss: 1.3225, Accuracy: 5283/10000 (53%)\n",
      "Train set: Average loss: 1.3089, Accuracy: 26720/50000 (53%)\n",
      "Test set: Average loss: 1.3209, Accuracy: 5299/10000 (53%)\n",
      "Train set: Average loss: 1.3064, Accuracy: 26801/50000 (54%)\n",
      "Test set: Average loss: 1.3156, Accuracy: 5308/10000 (53%)\n",
      "Train set: Average loss: 1.3047, Accuracy: 26829/50000 (54%)\n",
      "Test set: Average loss: 1.3123, Accuracy: 5329/10000 (53%)\n",
      "Train set: Average loss: 1.3014, Accuracy: 26938/50000 (54%)\n",
      "Test set: Average loss: 1.3167, Accuracy: 5300/10000 (53%)\n",
      "Train set: Average loss: 1.2997, Accuracy: 26979/50000 (54%)\n",
      "Test set: Average loss: 1.3065, Accuracy: 5333/10000 (53%)\n",
      "Train set: Average loss: 1.2975, Accuracy: 26954/50000 (54%)\n",
      "Test set: Average loss: 1.3088, Accuracy: 5299/10000 (53%)\n",
      "Train set: Average loss: 1.2956, Accuracy: 26990/50000 (54%)\n",
      "Test set: Average loss: 1.3134, Accuracy: 5300/10000 (53%)\n",
      "Train set: Average loss: 1.2934, Accuracy: 27114/50000 (54%)\n",
      "Test set: Average loss: 1.3035, Accuracy: 5353/10000 (54%)\n",
      "Train set: Average loss: 1.2907, Accuracy: 27160/50000 (54%)\n",
      "Test set: Average loss: 1.3005, Accuracy: 5377/10000 (54%)\n",
      "Train set: Average loss: 1.2884, Accuracy: 27157/50000 (54%)\n",
      "Test set: Average loss: 1.2971, Accuracy: 5391/10000 (54%)\n",
      "Train set: Average loss: 1.2870, Accuracy: 27225/50000 (54%)\n",
      "Test set: Average loss: 1.2963, Accuracy: 5374/10000 (54%)\n",
      "Train set: Average loss: 1.2845, Accuracy: 27286/50000 (55%)\n",
      "Test set: Average loss: 1.2946, Accuracy: 5401/10000 (54%)\n",
      "Train set: Average loss: 1.2818, Accuracy: 27309/50000 (55%)\n",
      "Test set: Average loss: 1.2966, Accuracy: 5350/10000 (54%)\n",
      "Train set: Average loss: 1.2795, Accuracy: 27345/50000 (55%)\n",
      "Test set: Average loss: 1.2961, Accuracy: 5382/10000 (54%)\n",
      "Train set: Average loss: 1.2781, Accuracy: 27365/50000 (55%)\n",
      "Test set: Average loss: 1.2894, Accuracy: 5393/10000 (54%)\n",
      "Train set: Average loss: 1.2759, Accuracy: 27322/50000 (55%)\n",
      "Test set: Average loss: 1.2869, Accuracy: 5405/10000 (54%)\n",
      "Train set: Average loss: 1.2739, Accuracy: 27473/50000 (55%)\n",
      "Test set: Average loss: 1.2857, Accuracy: 5423/10000 (54%)\n",
      "Train set: Average loss: 1.2720, Accuracy: 27497/50000 (55%)\n",
      "Test set: Average loss: 1.2841, Accuracy: 5401/10000 (54%)\n",
      "Train set: Average loss: 1.2695, Accuracy: 27548/50000 (55%)\n",
      "Test set: Average loss: 1.2851, Accuracy: 5404/10000 (54%)\n",
      "Train set: Average loss: 1.2675, Accuracy: 27558/50000 (55%)\n",
      "Test set: Average loss: 1.2821, Accuracy: 5421/10000 (54%)\n",
      "Train set: Average loss: 1.2663, Accuracy: 27619/50000 (55%)\n",
      "Test set: Average loss: 1.2808, Accuracy: 5440/10000 (54%)\n",
      "Train set: Average loss: 1.2643, Accuracy: 27564/50000 (55%)\n",
      "Test set: Average loss: 1.2770, Accuracy: 5464/10000 (55%)\n",
      "Train set: Average loss: 1.2621, Accuracy: 27645/50000 (55%)\n",
      "Test set: Average loss: 1.2754, Accuracy: 5435/10000 (54%)\n",
      "Train set: Average loss: 1.2605, Accuracy: 27657/50000 (55%)\n",
      "Test set: Average loss: 1.2718, Accuracy: 5472/10000 (55%)\n",
      "Train set: Average loss: 1.2580, Accuracy: 27646/50000 (55%)\n",
      "Test set: Average loss: 1.2823, Accuracy: 5443/10000 (54%)\n",
      "Train set: Average loss: 1.2563, Accuracy: 27747/50000 (55%)\n",
      "Test set: Average loss: 1.2757, Accuracy: 5467/10000 (55%)\n",
      "Train set: Average loss: 1.2551, Accuracy: 27759/50000 (56%)\n",
      "Test set: Average loss: 1.2778, Accuracy: 5390/10000 (54%)\n",
      "Train set: Average loss: 1.2526, Accuracy: 27800/50000 (56%)\n",
      "Test set: Average loss: 1.2628, Accuracy: 5476/10000 (55%)\n",
      "Train set: Average loss: 1.2509, Accuracy: 27733/50000 (55%)\n",
      "Test set: Average loss: 1.2636, Accuracy: 5466/10000 (55%)\n",
      "Train set: Average loss: 1.2485, Accuracy: 27856/50000 (56%)\n",
      "Test set: Average loss: 1.2681, Accuracy: 5460/10000 (55%)\n",
      "Train set: Average loss: 1.2474, Accuracy: 27971/50000 (56%)\n",
      "Test set: Average loss: 1.2625, Accuracy: 5487/10000 (55%)\n",
      "Train set: Average loss: 1.2461, Accuracy: 27911/50000 (56%)\n",
      "Test set: Average loss: 1.2644, Accuracy: 5505/10000 (55%)\n",
      "Train set: Average loss: 1.2443, Accuracy: 27957/50000 (56%)\n",
      "Test set: Average loss: 1.2611, Accuracy: 5504/10000 (55%)\n",
      "Train set: Average loss: 1.2417, Accuracy: 28006/50000 (56%)\n",
      "Test set: Average loss: 1.2630, Accuracy: 5478/10000 (55%)\n",
      "Train set: Average loss: 1.2406, Accuracy: 28047/50000 (56%)\n",
      "Test set: Average loss: 1.2529, Accuracy: 5538/10000 (55%)\n",
      "Train set: Average loss: 1.2381, Accuracy: 28096/50000 (56%)\n",
      "Test set: Average loss: 1.2578, Accuracy: 5511/10000 (55%)\n",
      "Train set: Average loss: 1.2366, Accuracy: 28160/50000 (56%)\n",
      "Test set: Average loss: 1.2565, Accuracy: 5534/10000 (55%)\n",
      "Train set: Average loss: 1.2345, Accuracy: 28134/50000 (56%)\n",
      "Test set: Average loss: 1.2497, Accuracy: 5541/10000 (55%)\n",
      "Train set: Average loss: 1.2327, Accuracy: 28127/50000 (56%)\n",
      "Test set: Average loss: 1.2520, Accuracy: 5537/10000 (55%)\n",
      "Train set: Average loss: 1.2311, Accuracy: 28175/50000 (56%)\n",
      "Test set: Average loss: 1.2533, Accuracy: 5510/10000 (55%)\n",
      "Train set: Average loss: 1.2304, Accuracy: 28280/50000 (57%)\n",
      "Test set: Average loss: 1.2497, Accuracy: 5547/10000 (55%)\n",
      "Train set: Average loss: 1.2276, Accuracy: 28312/50000 (57%)\n",
      "Test set: Average loss: 1.2490, Accuracy: 5524/10000 (55%)\n",
      "Train set: Average loss: 1.2266, Accuracy: 28241/50000 (56%)\n",
      "Test set: Average loss: 1.2454, Accuracy: 5544/10000 (55%)\n",
      "Train set: Average loss: 1.2257, Accuracy: 28328/50000 (57%)\n",
      "Test set: Average loss: 1.2431, Accuracy: 5582/10000 (56%)\n",
      "Train set: Average loss: 1.2212, Accuracy: 28355/50000 (57%)\n",
      "Test set: Average loss: 1.2490, Accuracy: 5542/10000 (55%)\n",
      "Train set: Average loss: 1.2210, Accuracy: 28398/50000 (57%)\n",
      "Test set: Average loss: 1.2457, Accuracy: 5541/10000 (55%)\n",
      "Train set: Average loss: 1.2195, Accuracy: 28451/50000 (57%)\n",
      "Test set: Average loss: 1.2411, Accuracy: 5576/10000 (56%)\n",
      "Train set: Average loss: 1.2173, Accuracy: 28492/50000 (57%)\n",
      "Test set: Average loss: 1.2662, Accuracy: 5509/10000 (55%)\n",
      "Train set: Average loss: 1.2169, Accuracy: 28374/50000 (57%)\n",
      "Test set: Average loss: 1.2355, Accuracy: 5603/10000 (56%)\n",
      "Train set: Average loss: 1.2146, Accuracy: 28444/50000 (57%)\n",
      "Test set: Average loss: 1.2382, Accuracy: 5584/10000 (56%)\n",
      "Train set: Average loss: 1.2125, Accuracy: 28527/50000 (57%)\n",
      "Test set: Average loss: 1.2345, Accuracy: 5604/10000 (56%)\n",
      "Train set: Average loss: 1.2101, Accuracy: 28541/50000 (57%)\n",
      "Test set: Average loss: 1.2372, Accuracy: 5605/10000 (56%)\n",
      "Train set: Average loss: 1.2084, Accuracy: 28616/50000 (57%)\n",
      "Test set: Average loss: 1.2311, Accuracy: 5624/10000 (56%)\n",
      "Train set: Average loss: 1.2070, Accuracy: 28726/50000 (57%)\n",
      "Test set: Average loss: 1.2335, Accuracy: 5595/10000 (56%)\n",
      "Train set: Average loss: 1.2061, Accuracy: 28603/50000 (57%)\n",
      "Test set: Average loss: 1.2255, Accuracy: 5632/10000 (56%)\n",
      "Train set: Average loss: 1.2052, Accuracy: 28684/50000 (57%)\n",
      "Test set: Average loss: 1.2306, Accuracy: 5632/10000 (56%)\n",
      "Train set: Average loss: 1.2024, Accuracy: 28777/50000 (58%)\n",
      "Test set: Average loss: 1.2245, Accuracy: 5616/10000 (56%)\n",
      "Train set: Average loss: 1.2016, Accuracy: 28695/50000 (57%)\n",
      "Test set: Average loss: 1.2260, Accuracy: 5638/10000 (56%)\n",
      "Train set: Average loss: 1.1992, Accuracy: 28741/50000 (57%)\n",
      "Test set: Average loss: 1.2304, Accuracy: 5618/10000 (56%)\n",
      "Train set: Average loss: 1.1977, Accuracy: 28803/50000 (58%)\n",
      "Test set: Average loss: 1.2248, Accuracy: 5627/10000 (56%)\n",
      "Train set: Average loss: 1.1961, Accuracy: 28766/50000 (58%)\n",
      "Test set: Average loss: 1.2259, Accuracy: 5630/10000 (56%)\n",
      "Train set: Average loss: 1.1943, Accuracy: 28894/50000 (58%)\n",
      "Test set: Average loss: 1.2243, Accuracy: 5605/10000 (56%)\n",
      "Train set: Average loss: 1.1925, Accuracy: 28940/50000 (58%)\n",
      "Test set: Average loss: 1.2182, Accuracy: 5652/10000 (57%)\n",
      "Train set: Average loss: 1.1913, Accuracy: 28888/50000 (58%)\n",
      "Test set: Average loss: 1.2183, Accuracy: 5648/10000 (56%)\n",
      "Train set: Average loss: 1.1905, Accuracy: 28917/50000 (58%)\n",
      "Test set: Average loss: 1.2156, Accuracy: 5670/10000 (57%)\n",
      "Train set: Average loss: 1.1891, Accuracy: 28963/50000 (58%)\n",
      "Test set: Average loss: 1.2132, Accuracy: 5669/10000 (57%)\n",
      "Train set: Average loss: 1.1879, Accuracy: 28997/50000 (58%)\n",
      "Test set: Average loss: 1.2154, Accuracy: 5657/10000 (57%)\n",
      "Train set: Average loss: 1.1847, Accuracy: 29135/50000 (58%)\n",
      "Test set: Average loss: 1.2092, Accuracy: 5707/10000 (57%)\n",
      "Train set: Average loss: 1.1848, Accuracy: 29047/50000 (58%)\n",
      "Test set: Average loss: 1.2232, Accuracy: 5678/10000 (57%)\n",
      "Train set: Average loss: 1.1825, Accuracy: 29123/50000 (58%)\n",
      "Test set: Average loss: 1.2109, Accuracy: 5689/10000 (57%)\n",
      "Train set: Average loss: 1.1811, Accuracy: 29117/50000 (58%)\n",
      "Test set: Average loss: 1.2107, Accuracy: 5676/10000 (57%)\n",
      "Train set: Average loss: 1.1807, Accuracy: 29196/50000 (58%)\n",
      "Test set: Average loss: 1.2223, Accuracy: 5646/10000 (56%)\n",
      "Train set: Average loss: 1.1781, Accuracy: 29180/50000 (58%)\n",
      "Test set: Average loss: 1.2097, Accuracy: 5675/10000 (57%)\n",
      "Train set: Average loss: 1.1755, Accuracy: 29190/50000 (58%)\n",
      "Test set: Average loss: 1.2031, Accuracy: 5724/10000 (57%)\n",
      "Train set: Average loss: 1.1762, Accuracy: 29234/50000 (58%)\n",
      "Test set: Average loss: 1.2036, Accuracy: 5714/10000 (57%)\n",
      "Train set: Average loss: 1.1740, Accuracy: 29265/50000 (59%)\n",
      "Test set: Average loss: 1.2044, Accuracy: 5699/10000 (57%)\n",
      "Train set: Average loss: 1.1719, Accuracy: 29345/50000 (59%)\n",
      "Test set: Average loss: 1.1972, Accuracy: 5747/10000 (57%)\n",
      "Train set: Average loss: 1.1699, Accuracy: 29378/50000 (59%)\n",
      "Test set: Average loss: 1.2027, Accuracy: 5703/10000 (57%)\n",
      "Train set: Average loss: 1.1702, Accuracy: 29275/50000 (59%)\n",
      "Test set: Average loss: 1.1955, Accuracy: 5765/10000 (58%)\n",
      "Train set: Average loss: 1.1669, Accuracy: 29376/50000 (59%)\n",
      "Test set: Average loss: 1.1977, Accuracy: 5726/10000 (57%)\n",
      "Train set: Average loss: 1.1663, Accuracy: 29440/50000 (59%)\n",
      "Test set: Average loss: 1.1943, Accuracy: 5756/10000 (58%)\n",
      "Train set: Average loss: 1.1648, Accuracy: 29432/50000 (59%)\n",
      "Test set: Average loss: 1.1936, Accuracy: 5755/10000 (58%)\n",
      "Train set: Average loss: 1.1624, Accuracy: 29500/50000 (59%)\n",
      "Test set: Average loss: 1.1939, Accuracy: 5744/10000 (57%)\n",
      "Train set: Average loss: 1.1606, Accuracy: 29502/50000 (59%)\n",
      "Test set: Average loss: 1.1972, Accuracy: 5743/10000 (57%)\n",
      "Train set: Average loss: 1.1611, Accuracy: 29483/50000 (59%)\n",
      "Test set: Average loss: 1.1932, Accuracy: 5716/10000 (57%)\n",
      "Train set: Average loss: 1.1589, Accuracy: 29658/50000 (59%)\n",
      "Test set: Average loss: 1.1915, Accuracy: 5748/10000 (57%)\n",
      "Train set: Average loss: 1.1581, Accuracy: 29543/50000 (59%)\n",
      "Test set: Average loss: 1.1853, Accuracy: 5788/10000 (58%)\n",
      "Train set: Average loss: 1.1562, Accuracy: 29629/50000 (59%)\n",
      "Test set: Average loss: 1.1858, Accuracy: 5764/10000 (58%)\n",
      "Train set: Average loss: 1.1548, Accuracy: 29549/50000 (59%)\n",
      "Test set: Average loss: 1.1877, Accuracy: 5770/10000 (58%)\n",
      "Train set: Average loss: 1.1542, Accuracy: 29683/50000 (59%)\n",
      "Test set: Average loss: 1.2067, Accuracy: 5683/10000 (57%)\n",
      "Train set: Average loss: 1.1510, Accuracy: 29776/50000 (60%)\n",
      "Test set: Average loss: 1.1801, Accuracy: 5799/10000 (58%)\n",
      "Train set: Average loss: 1.1508, Accuracy: 29728/50000 (59%)\n",
      "Test set: Average loss: 1.1839, Accuracy: 5800/10000 (58%)\n",
      "Train set: Average loss: 1.1484, Accuracy: 29740/50000 (59%)\n",
      "Test set: Average loss: 1.1811, Accuracy: 5777/10000 (58%)\n",
      "Train set: Average loss: 1.1462, Accuracy: 29753/50000 (60%)\n",
      "Test set: Average loss: 1.1875, Accuracy: 5753/10000 (58%)\n",
      "Train set: Average loss: 1.1456, Accuracy: 29857/50000 (60%)\n",
      "Test set: Average loss: 1.1861, Accuracy: 5805/10000 (58%)\n",
      "Train set: Average loss: 1.1450, Accuracy: 29856/50000 (60%)\n",
      "Test set: Average loss: 1.1819, Accuracy: 5831/10000 (58%)\n",
      "Train set: Average loss: 1.1436, Accuracy: 29877/50000 (60%)\n",
      "Test set: Average loss: 1.1834, Accuracy: 5787/10000 (58%)\n",
      "Train set: Average loss: 1.1421, Accuracy: 29928/50000 (60%)\n",
      "Test set: Average loss: 1.1794, Accuracy: 5793/10000 (58%)\n",
      "Train set: Average loss: 1.1416, Accuracy: 29936/50000 (60%)\n",
      "Test set: Average loss: 1.1885, Accuracy: 5761/10000 (58%)\n",
      "Train set: Average loss: 1.1393, Accuracy: 30002/50000 (60%)\n",
      "Test set: Average loss: 1.1858, Accuracy: 5817/10000 (58%)\n",
      "Train set: Average loss: 1.1384, Accuracy: 29962/50000 (60%)\n",
      "Test set: Average loss: 1.1729, Accuracy: 5809/10000 (58%)\n",
      "Train set: Average loss: 1.1358, Accuracy: 30041/50000 (60%)\n",
      "Test set: Average loss: 1.1887, Accuracy: 5761/10000 (58%)\n",
      "Train set: Average loss: 1.1358, Accuracy: 30039/50000 (60%)\n",
      "Test set: Average loss: 1.1737, Accuracy: 5833/10000 (58%)\n",
      "Train set: Average loss: 1.1346, Accuracy: 30066/50000 (60%)\n",
      "Test set: Average loss: 1.1859, Accuracy: 5753/10000 (58%)\n",
      "Train set: Average loss: 1.1321, Accuracy: 30072/50000 (60%)\n",
      "Test set: Average loss: 1.1686, Accuracy: 5846/10000 (58%)\n",
      "Train set: Average loss: 1.1321, Accuracy: 30063/50000 (60%)\n",
      "Test set: Average loss: 1.1713, Accuracy: 5818/10000 (58%)\n",
      "Train set: Average loss: 1.1291, Accuracy: 30051/50000 (60%)\n",
      "Test set: Average loss: 1.1775, Accuracy: 5799/10000 (58%)\n",
      "Train set: Average loss: 1.1287, Accuracy: 30184/50000 (60%)\n",
      "Test set: Average loss: 1.1660, Accuracy: 5843/10000 (58%)\n",
      "Train set: Average loss: 1.1256, Accuracy: 30239/50000 (60%)\n",
      "Test set: Average loss: 1.1679, Accuracy: 5849/10000 (58%)\n",
      "Train set: Average loss: 1.1259, Accuracy: 30162/50000 (60%)\n",
      "Test set: Average loss: 1.1651, Accuracy: 5840/10000 (58%)\n",
      "Train set: Average loss: 1.1243, Accuracy: 30222/50000 (60%)\n",
      "Test set: Average loss: 1.1663, Accuracy: 5841/10000 (58%)\n",
      "Train set: Average loss: 1.1240, Accuracy: 30282/50000 (61%)\n",
      "Test set: Average loss: 1.1633, Accuracy: 5874/10000 (59%)\n",
      "Train set: Average loss: 1.1207, Accuracy: 30313/50000 (61%)\n",
      "Test set: Average loss: 1.1622, Accuracy: 5847/10000 (58%)\n",
      "Train set: Average loss: 1.1211, Accuracy: 30245/50000 (60%)\n",
      "Test set: Average loss: 1.1599, Accuracy: 5895/10000 (59%)\n",
      "Train set: Average loss: 1.1204, Accuracy: 30270/50000 (61%)\n",
      "Test set: Average loss: 1.1662, Accuracy: 5832/10000 (58%)\n",
      "Train set: Average loss: 1.1189, Accuracy: 30405/50000 (61%)\n",
      "Test set: Average loss: 1.1635, Accuracy: 5850/10000 (58%)\n",
      "Train set: Average loss: 1.1184, Accuracy: 30353/50000 (61%)\n",
      "Test set: Average loss: 1.1692, Accuracy: 5855/10000 (59%)\n",
      "Train set: Average loss: 1.1134, Accuracy: 30439/50000 (61%)\n",
      "Test set: Average loss: 1.1586, Accuracy: 5858/10000 (59%)\n",
      "Train set: Average loss: 1.1139, Accuracy: 30482/50000 (61%)\n",
      "Test set: Average loss: 1.1665, Accuracy: 5857/10000 (59%)\n",
      "Train set: Average loss: 1.1121, Accuracy: 30411/50000 (61%)\n",
      "Test set: Average loss: 1.1713, Accuracy: 5801/10000 (58%)\n",
      "Train set: Average loss: 1.1115, Accuracy: 30504/50000 (61%)\n",
      "Test set: Average loss: 1.1745, Accuracy: 5807/10000 (58%)\n",
      "Train set: Average loss: 1.1101, Accuracy: 30508/50000 (61%)\n",
      "Test set: Average loss: 1.1554, Accuracy: 5888/10000 (59%)\n",
      "Train set: Average loss: 1.1081, Accuracy: 30518/50000 (61%)\n",
      "Test set: Average loss: 1.1602, Accuracy: 5867/10000 (59%)\n",
      "Train set: Average loss: 1.1077, Accuracy: 30579/50000 (61%)\n",
      "Test set: Average loss: 1.1578, Accuracy: 5890/10000 (59%)\n",
      "Train set: Average loss: 1.1052, Accuracy: 30583/50000 (61%)\n",
      "Test set: Average loss: 1.1461, Accuracy: 5915/10000 (59%)\n",
      "Train set: Average loss: 1.1055, Accuracy: 30648/50000 (61%)\n",
      "Test set: Average loss: 1.1484, Accuracy: 5925/10000 (59%)\n",
      "Train set: Average loss: 1.1041, Accuracy: 30567/50000 (61%)\n",
      "Test set: Average loss: 1.1514, Accuracy: 5879/10000 (59%)\n",
      "Train set: Average loss: 1.1017, Accuracy: 30619/50000 (61%)\n",
      "Test set: Average loss: 1.1443, Accuracy: 5909/10000 (59%)\n",
      "Train set: Average loss: 1.1010, Accuracy: 30658/50000 (61%)\n",
      "Test set: Average loss: 1.1549, Accuracy: 5899/10000 (59%)\n",
      "Train set: Average loss: 1.1021, Accuracy: 30666/50000 (61%)\n",
      "Test set: Average loss: 1.1439, Accuracy: 5932/10000 (59%)\n",
      "Train set: Average loss: 1.0986, Accuracy: 30721/50000 (61%)\n",
      "Test set: Average loss: 1.1441, Accuracy: 5938/10000 (59%)\n",
      "Train set: Average loss: 1.0974, Accuracy: 30750/50000 (62%)\n",
      "Test set: Average loss: 1.1490, Accuracy: 5912/10000 (59%)\n",
      "Train set: Average loss: 1.0969, Accuracy: 30674/50000 (61%)\n",
      "Test set: Average loss: 1.1476, Accuracy: 5886/10000 (59%)\n",
      "Train set: Average loss: 1.0953, Accuracy: 30850/50000 (62%)\n",
      "Test set: Average loss: 1.1387, Accuracy: 5925/10000 (59%)\n",
      "Train set: Average loss: 1.0940, Accuracy: 30840/50000 (62%)\n",
      "Test set: Average loss: 1.1574, Accuracy: 5878/10000 (59%)\n",
      "Train set: Average loss: 1.0924, Accuracy: 30837/50000 (62%)\n",
      "Test set: Average loss: 1.1629, Accuracy: 5883/10000 (59%)\n",
      "Train set: Average loss: 1.0937, Accuracy: 30894/50000 (62%)\n",
      "Test set: Average loss: 1.1414, Accuracy: 5906/10000 (59%)\n",
      "Train set: Average loss: 1.0908, Accuracy: 30848/50000 (62%)\n",
      "Test set: Average loss: 1.1373, Accuracy: 5933/10000 (59%)\n",
      "Train set: Average loss: 1.0895, Accuracy: 30898/50000 (62%)\n",
      "Test set: Average loss: 1.1388, Accuracy: 5950/10000 (60%)\n",
      "Train set: Average loss: 1.0891, Accuracy: 30884/50000 (62%)\n",
      "Test set: Average loss: 1.1427, Accuracy: 5932/10000 (59%)\n",
      "Train set: Average loss: 1.0864, Accuracy: 30892/50000 (62%)\n",
      "Test set: Average loss: 1.1505, Accuracy: 5892/10000 (59%)\n",
      "Train set: Average loss: 1.0863, Accuracy: 30989/50000 (62%)\n",
      "Test set: Average loss: 1.1339, Accuracy: 5945/10000 (59%)\n",
      "Train set: Average loss: 1.0845, Accuracy: 31005/50000 (62%)\n",
      "Test set: Average loss: 1.1524, Accuracy: 5901/10000 (59%)\n",
      "Train set: Average loss: 1.0828, Accuracy: 31000/50000 (62%)\n",
      "Test set: Average loss: 1.1381, Accuracy: 5906/10000 (59%)\n",
      "Train set: Average loss: 1.0819, Accuracy: 31055/50000 (62%)\n",
      "Test set: Average loss: 1.1376, Accuracy: 5929/10000 (59%)\n",
      "Train set: Average loss: 1.0832, Accuracy: 31018/50000 (62%)\n",
      "Test set: Average loss: 1.1343, Accuracy: 5973/10000 (60%)\n",
      "Train set: Average loss: 1.0789, Accuracy: 31151/50000 (62%)\n",
      "Test set: Average loss: 1.1274, Accuracy: 5976/10000 (60%)\n",
      "Train set: Average loss: 1.0789, Accuracy: 31054/50000 (62%)\n",
      "Test set: Average loss: 1.1275, Accuracy: 5999/10000 (60%)\n",
      "Train set: Average loss: 1.0783, Accuracy: 31071/50000 (62%)\n",
      "Test set: Average loss: 1.1418, Accuracy: 5904/10000 (59%)\n",
      "Train set: Average loss: 1.0755, Accuracy: 31100/50000 (62%)\n",
      "Test set: Average loss: 1.1301, Accuracy: 5966/10000 (60%)\n",
      "Train set: Average loss: 1.0755, Accuracy: 31103/50000 (62%)\n",
      "Test set: Average loss: 1.1322, Accuracy: 5977/10000 (60%)\n",
      "Train set: Average loss: 1.0746, Accuracy: 31152/50000 (62%)\n",
      "Test set: Average loss: 1.1450, Accuracy: 5936/10000 (59%)\n",
      "Train set: Average loss: 1.0729, Accuracy: 31242/50000 (62%)\n",
      "Test set: Average loss: 1.1316, Accuracy: 5957/10000 (60%)\n",
      "Train set: Average loss: 1.0730, Accuracy: 31224/50000 (62%)\n",
      "Test set: Average loss: 1.1345, Accuracy: 5948/10000 (59%)\n",
      "Train set: Average loss: 1.0709, Accuracy: 31274/50000 (63%)\n",
      "Test set: Average loss: 1.1407, Accuracy: 5937/10000 (59%)\n",
      "Train set: Average loss: 1.0695, Accuracy: 31285/50000 (63%)\n",
      "Test set: Average loss: 1.1272, Accuracy: 5985/10000 (60%)\n",
      "Train set: Average loss: 1.0689, Accuracy: 31337/50000 (63%)\n",
      "Test set: Average loss: 1.1277, Accuracy: 5984/10000 (60%)\n",
      "Train set: Average loss: 1.0668, Accuracy: 31318/50000 (63%)\n",
      "Test set: Average loss: 1.1247, Accuracy: 6002/10000 (60%)\n",
      "Train set: Average loss: 1.0683, Accuracy: 31281/50000 (63%)\n",
      "Test set: Average loss: 1.1382, Accuracy: 5938/10000 (59%)\n",
      "Train set: Average loss: 1.0650, Accuracy: 31380/50000 (63%)\n",
      "Test set: Average loss: 1.1228, Accuracy: 6004/10000 (60%)\n",
      "Train set: Average loss: 1.0655, Accuracy: 31374/50000 (63%)\n",
      "Test set: Average loss: 1.1311, Accuracy: 5954/10000 (60%)\n",
      "Train set: Average loss: 1.0640, Accuracy: 31383/50000 (63%)\n",
      "Test set: Average loss: 1.1214, Accuracy: 5995/10000 (60%)\n",
      "Train set: Average loss: 1.0626, Accuracy: 31355/50000 (63%)\n",
      "Test set: Average loss: 1.1275, Accuracy: 5969/10000 (60%)\n",
      "Train set: Average loss: 1.0612, Accuracy: 31407/50000 (63%)\n",
      "Test set: Average loss: 1.1188, Accuracy: 5998/10000 (60%)\n",
      "Train set: Average loss: 1.0595, Accuracy: 31475/50000 (63%)\n",
      "Test set: Average loss: 1.1160, Accuracy: 6016/10000 (60%)\n",
      "Train set: Average loss: 1.0601, Accuracy: 31404/50000 (63%)\n",
      "Test set: Average loss: 1.1197, Accuracy: 6009/10000 (60%)\n",
      "Train set: Average loss: 1.0579, Accuracy: 31506/50000 (63%)\n",
      "Test set: Average loss: 1.1332, Accuracy: 5948/10000 (59%)\n",
      "Train set: Average loss: 1.0570, Accuracy: 31460/50000 (63%)\n",
      "Test set: Average loss: 1.1234, Accuracy: 5992/10000 (60%)\n",
      "Train set: Average loss: 1.0569, Accuracy: 31533/50000 (63%)\n",
      "Test set: Average loss: 1.1236, Accuracy: 6011/10000 (60%)\n",
      "Train set: Average loss: 1.0554, Accuracy: 31516/50000 (63%)\n",
      "Test set: Average loss: 1.1197, Accuracy: 5982/10000 (60%)\n",
      "Train set: Average loss: 1.0553, Accuracy: 31539/50000 (63%)\n",
      "Test set: Average loss: 1.1220, Accuracy: 6003/10000 (60%)\n",
      "Train set: Average loss: 1.0528, Accuracy: 31542/50000 (63%)\n",
      "Test set: Average loss: 1.1183, Accuracy: 6036/10000 (60%)\n",
      "Train set: Average loss: 1.0526, Accuracy: 31592/50000 (63%)\n",
      "Test set: Average loss: 1.1092, Accuracy: 6048/10000 (60%)\n",
      "Train set: Average loss: 1.0505, Accuracy: 31585/50000 (63%)\n",
      "Test set: Average loss: 1.1222, Accuracy: 5985/10000 (60%)\n",
      "Train set: Average loss: 1.0501, Accuracy: 31653/50000 (63%)\n",
      "Test set: Average loss: 1.1308, Accuracy: 5961/10000 (60%)\n",
      "Train set: Average loss: 1.0484, Accuracy: 31696/50000 (63%)\n",
      "Test set: Average loss: 1.1097, Accuracy: 6019/10000 (60%)\n",
      "Train set: Average loss: 1.0483, Accuracy: 31628/50000 (63%)\n",
      "Test set: Average loss: 1.1091, Accuracy: 6038/10000 (60%)\n",
      "Train set: Average loss: 1.0474, Accuracy: 31624/50000 (63%)\n",
      "Test set: Average loss: 1.1083, Accuracy: 6056/10000 (61%)\n",
      "Train set: Average loss: 1.0464, Accuracy: 31717/50000 (63%)\n",
      "Test set: Average loss: 1.1047, Accuracy: 6067/10000 (61%)\n",
      "Train set: Average loss: 1.0448, Accuracy: 31728/50000 (63%)\n",
      "Test set: Average loss: 1.1101, Accuracy: 6024/10000 (60%)\n",
      "Train set: Average loss: 1.0448, Accuracy: 31719/50000 (63%)\n",
      "Test set: Average loss: 1.1081, Accuracy: 6058/10000 (61%)\n",
      "Train set: Average loss: 1.0430, Accuracy: 31805/50000 (64%)\n",
      "Test set: Average loss: 1.1100, Accuracy: 6040/10000 (60%)\n",
      "Train set: Average loss: 1.0431, Accuracy: 31763/50000 (64%)\n",
      "Test set: Average loss: 1.1078, Accuracy: 6028/10000 (60%)\n",
      "Train set: Average loss: 1.0404, Accuracy: 31864/50000 (64%)\n",
      "Test set: Average loss: 1.1037, Accuracy: 6064/10000 (61%)\n",
      "Train set: Average loss: 1.0422, Accuracy: 31736/50000 (63%)\n",
      "Test set: Average loss: 1.1049, Accuracy: 6035/10000 (60%)\n",
      "Train set: Average loss: 1.0404, Accuracy: 31751/50000 (64%)\n",
      "Test set: Average loss: 1.1008, Accuracy: 6052/10000 (61%)\n",
      "Train set: Average loss: 1.0382, Accuracy: 31919/50000 (64%)\n",
      "Test set: Average loss: 1.1032, Accuracy: 6065/10000 (61%)\n",
      "Train set: Average loss: 1.0381, Accuracy: 31928/50000 (64%)\n",
      "Test set: Average loss: 1.1066, Accuracy: 6035/10000 (60%)\n",
      "Train set: Average loss: 1.0360, Accuracy: 31794/50000 (64%)\n",
      "Test set: Average loss: 1.1082, Accuracy: 6033/10000 (60%)\n",
      "Train set: Average loss: 1.0358, Accuracy: 31892/50000 (64%)\n",
      "Test set: Average loss: 1.1061, Accuracy: 6035/10000 (60%)\n",
      "Train set: Average loss: 1.0341, Accuracy: 31931/50000 (64%)\n",
      "Test set: Average loss: 1.0978, Accuracy: 6074/10000 (61%)\n",
      "Train set: Average loss: 1.0337, Accuracy: 31878/50000 (64%)\n",
      "Test set: Average loss: 1.0951, Accuracy: 6083/10000 (61%)\n",
      "Train set: Average loss: 1.0333, Accuracy: 31920/50000 (64%)\n",
      "Test set: Average loss: 1.1014, Accuracy: 6077/10000 (61%)\n",
      "Train set: Average loss: 1.0311, Accuracy: 31956/50000 (64%)\n",
      "Test set: Average loss: 1.0953, Accuracy: 6076/10000 (61%)\n",
      "Train set: Average loss: 1.0312, Accuracy: 31995/50000 (64%)\n",
      "Test set: Average loss: 1.0963, Accuracy: 6085/10000 (61%)\n",
      "Train set: Average loss: 1.0296, Accuracy: 32057/50000 (64%)\n",
      "Test set: Average loss: 1.0987, Accuracy: 6101/10000 (61%)\n",
      "Train set: Average loss: 1.0283, Accuracy: 31978/50000 (64%)\n",
      "Test set: Average loss: 1.0955, Accuracy: 6088/10000 (61%)\n",
      "Train set: Average loss: 1.0277, Accuracy: 32068/50000 (64%)\n",
      "Test set: Average loss: 1.0976, Accuracy: 6088/10000 (61%)\n",
      "Train set: Average loss: 1.0276, Accuracy: 32001/50000 (64%)\n",
      "Test set: Average loss: 1.0966, Accuracy: 6072/10000 (61%)\n",
      "Train set: Average loss: 1.0271, Accuracy: 32046/50000 (64%)\n",
      "Test set: Average loss: 1.0992, Accuracy: 6091/10000 (61%)\n",
      "Train set: Average loss: 1.0250, Accuracy: 32047/50000 (64%)\n",
      "Test set: Average loss: 1.0931, Accuracy: 6092/10000 (61%)\n",
      "Train set: Average loss: 1.0241, Accuracy: 32119/50000 (64%)\n",
      "Test set: Average loss: 1.1026, Accuracy: 6063/10000 (61%)\n",
      "Train set: Average loss: 1.0233, Accuracy: 32173/50000 (64%)\n",
      "Test set: Average loss: 1.0921, Accuracy: 6092/10000 (61%)\n",
      "Train set: Average loss: 1.0218, Accuracy: 32162/50000 (64%)\n",
      "Test set: Average loss: 1.0926, Accuracy: 6109/10000 (61%)\n",
      "Train set: Average loss: 1.0204, Accuracy: 32165/50000 (64%)\n",
      "Test set: Average loss: 1.0959, Accuracy: 6113/10000 (61%)\n",
      "Train set: Average loss: 1.0196, Accuracy: 32274/50000 (65%)\n",
      "Test set: Average loss: 1.0982, Accuracy: 6080/10000 (61%)\n",
      "Train set: Average loss: 1.0204, Accuracy: 32191/50000 (64%)\n",
      "Test set: Average loss: 1.1155, Accuracy: 6001/10000 (60%)\n",
      "Train set: Average loss: 1.0181, Accuracy: 32203/50000 (64%)\n",
      "Test set: Average loss: 1.0916, Accuracy: 6086/10000 (61%)\n",
      "Train set: Average loss: 1.0183, Accuracy: 32213/50000 (64%)\n",
      "Test set: Average loss: 1.0942, Accuracy: 6098/10000 (61%)\n",
      "Train set: Average loss: 1.0176, Accuracy: 32216/50000 (64%)\n",
      "Test set: Average loss: 1.1028, Accuracy: 6083/10000 (61%)\n",
      "Train set: Average loss: 1.0171, Accuracy: 32199/50000 (64%)\n",
      "Test set: Average loss: 1.0881, Accuracy: 6119/10000 (61%)\n",
      "Train set: Average loss: 1.0158, Accuracy: 32324/50000 (65%)\n",
      "Test set: Average loss: 1.0900, Accuracy: 6108/10000 (61%)\n",
      "Train set: Average loss: 1.0151, Accuracy: 32166/50000 (64%)\n",
      "Test set: Average loss: 1.1074, Accuracy: 6068/10000 (61%)\n",
      "Train set: Average loss: 1.0149, Accuracy: 32235/50000 (64%)\n",
      "Test set: Average loss: 1.0868, Accuracy: 6119/10000 (61%)\n",
      "Train set: Average loss: 1.0134, Accuracy: 32389/50000 (65%)\n",
      "Test set: Average loss: 1.1094, Accuracy: 6052/10000 (61%)\n",
      "Train set: Average loss: 1.0119, Accuracy: 32320/50000 (65%)\n",
      "Test set: Average loss: 1.1122, Accuracy: 6024/10000 (60%)\n",
      "Train set: Average loss: 1.0128, Accuracy: 32334/50000 (65%)\n",
      "Test set: Average loss: 1.1071, Accuracy: 6068/10000 (61%)\n",
      "Train set: Average loss: 1.0112, Accuracy: 32292/50000 (65%)\n",
      "Test set: Average loss: 1.0822, Accuracy: 6103/10000 (61%)\n",
      "Train set: Average loss: 1.0112, Accuracy: 32243/50000 (64%)\n",
      "Test set: Average loss: 1.0850, Accuracy: 6096/10000 (61%)\n",
      "Train set: Average loss: 1.0094, Accuracy: 32371/50000 (65%)\n",
      "Test set: Average loss: 1.0837, Accuracy: 6134/10000 (61%)\n",
      "Train set: Average loss: 1.0082, Accuracy: 32294/50000 (65%)\n",
      "Test set: Average loss: 1.0854, Accuracy: 6117/10000 (61%)\n",
      "Train set: Average loss: 1.0072, Accuracy: 32417/50000 (65%)\n",
      "Test set: Average loss: 1.0874, Accuracy: 6144/10000 (61%)\n",
      "Train set: Average loss: 1.0077, Accuracy: 32375/50000 (65%)\n",
      "Test set: Average loss: 1.0957, Accuracy: 6106/10000 (61%)\n",
      "Train set: Average loss: 1.0063, Accuracy: 32449/50000 (65%)\n",
      "Test set: Average loss: 1.0788, Accuracy: 6167/10000 (62%)\n",
      "Train set: Average loss: 1.0057, Accuracy: 32355/50000 (65%)\n",
      "Test set: Average loss: 1.0783, Accuracy: 6157/10000 (62%)\n",
      "Train set: Average loss: 1.0048, Accuracy: 32378/50000 (65%)\n",
      "Test set: Average loss: 1.0825, Accuracy: 6162/10000 (62%)\n",
      "Train set: Average loss: 1.0029, Accuracy: 32421/50000 (65%)\n",
      "Test set: Average loss: 1.0867, Accuracy: 6153/10000 (62%)\n",
      "Train set: Average loss: 1.0030, Accuracy: 32396/50000 (65%)\n",
      "Test set: Average loss: 1.0776, Accuracy: 6144/10000 (61%)\n",
      "Train set: Average loss: 1.0015, Accuracy: 32480/50000 (65%)\n",
      "Test set: Average loss: 1.0847, Accuracy: 6121/10000 (61%)\n",
      "Train set: Average loss: 1.0026, Accuracy: 32458/50000 (65%)\n",
      "Test set: Average loss: 1.0778, Accuracy: 6142/10000 (61%)\n",
      "Train set: Average loss: 0.9995, Accuracy: 32530/50000 (65%)\n",
      "Test set: Average loss: 1.0752, Accuracy: 6163/10000 (62%)\n",
      "Train set: Average loss: 1.0013, Accuracy: 32474/50000 (65%)\n",
      "Test set: Average loss: 1.0987, Accuracy: 6081/10000 (61%)\n",
      "Train set: Average loss: 0.9989, Accuracy: 32532/50000 (65%)\n",
      "Test set: Average loss: 1.0900, Accuracy: 6107/10000 (61%)\n",
      "Train set: Average loss: 0.9977, Accuracy: 32529/50000 (65%)\n",
      "Test set: Average loss: 1.0744, Accuracy: 6164/10000 (62%)\n",
      "Train set: Average loss: 0.9959, Accuracy: 32570/50000 (65%)\n",
      "Test set: Average loss: 1.0902, Accuracy: 6136/10000 (61%)\n",
      "Train set: Average loss: 0.9962, Accuracy: 32575/50000 (65%)\n",
      "Test set: Average loss: 1.0799, Accuracy: 6175/10000 (62%)\n",
      "Train set: Average loss: 0.9967, Accuracy: 32507/50000 (65%)\n",
      "Test set: Average loss: 1.0753, Accuracy: 6170/10000 (62%)\n",
      "Train set: Average loss: 0.9947, Accuracy: 32669/50000 (65%)\n",
      "Test set: Average loss: 1.0729, Accuracy: 6174/10000 (62%)\n",
      "Train set: Average loss: 0.9928, Accuracy: 32586/50000 (65%)\n",
      "Test set: Average loss: 1.0711, Accuracy: 6172/10000 (62%)\n",
      "Train set: Average loss: 0.9914, Accuracy: 32746/50000 (65%)\n",
      "Test set: Average loss: 1.0861, Accuracy: 6103/10000 (61%)\n",
      "Train set: Average loss: 0.9926, Accuracy: 32647/50000 (65%)\n",
      "Test set: Average loss: 1.0999, Accuracy: 6109/10000 (61%)\n",
      "Train set: Average loss: 0.9901, Accuracy: 32744/50000 (65%)\n",
      "Test set: Average loss: 1.0739, Accuracy: 6177/10000 (62%)\n",
      "Train set: Average loss: 0.9909, Accuracy: 32607/50000 (65%)\n",
      "Test set: Average loss: 1.1028, Accuracy: 6065/10000 (61%)\n",
      "Train set: Average loss: 0.9903, Accuracy: 32670/50000 (65%)\n",
      "Test set: Average loss: 1.0751, Accuracy: 6173/10000 (62%)\n",
      "Train set: Average loss: 0.9893, Accuracy: 32696/50000 (65%)\n",
      "Test set: Average loss: 1.0760, Accuracy: 6156/10000 (62%)\n",
      "Train set: Average loss: 0.9888, Accuracy: 32677/50000 (65%)\n",
      "Test set: Average loss: 1.0758, Accuracy: 6160/10000 (62%)\n",
      "Train set: Average loss: 0.9868, Accuracy: 32739/50000 (65%)\n",
      "Test set: Average loss: 1.0899, Accuracy: 6180/10000 (62%)\n",
      "Train set: Average loss: 0.9869, Accuracy: 32709/50000 (65%)\n",
      "Test set: Average loss: 1.0781, Accuracy: 6171/10000 (62%)\n",
      "Train set: Average loss: 0.9871, Accuracy: 32757/50000 (66%)\n",
      "Test set: Average loss: 1.0865, Accuracy: 6197/10000 (62%)\n",
      "Train set: Average loss: 0.9854, Accuracy: 32750/50000 (66%)\n",
      "Test set: Average loss: 1.0880, Accuracy: 6123/10000 (61%)\n",
      "Train set: Average loss: 0.9841, Accuracy: 32769/50000 (66%)\n",
      "Test set: Average loss: 1.0795, Accuracy: 6165/10000 (62%)\n",
      "Train set: Average loss: 0.9833, Accuracy: 32765/50000 (66%)\n",
      "Test set: Average loss: 1.0762, Accuracy: 6153/10000 (62%)\n",
      "Train set: Average loss: 0.9846, Accuracy: 32763/50000 (66%)\n",
      "Test set: Average loss: 1.0699, Accuracy: 6178/10000 (62%)\n",
      "Train set: Average loss: 0.9812, Accuracy: 32844/50000 (66%)\n",
      "Test set: Average loss: 1.0737, Accuracy: 6163/10000 (62%)\n",
      "Train set: Average loss: 0.9816, Accuracy: 32819/50000 (66%)\n",
      "Test set: Average loss: 1.0842, Accuracy: 6145/10000 (61%)\n",
      "Train set: Average loss: 0.9810, Accuracy: 32866/50000 (66%)\n",
      "Test set: Average loss: 1.0753, Accuracy: 6160/10000 (62%)\n",
      "Train set: Average loss: 0.9811, Accuracy: 32890/50000 (66%)\n",
      "Test set: Average loss: 1.0712, Accuracy: 6175/10000 (62%)\n",
      "Train set: Average loss: 0.9795, Accuracy: 32912/50000 (66%)\n",
      "Test set: Average loss: 1.0646, Accuracy: 6201/10000 (62%)\n",
      "Train set: Average loss: 0.9792, Accuracy: 32836/50000 (66%)\n",
      "Test set: Average loss: 1.0682, Accuracy: 6195/10000 (62%)\n",
      "Train set: Average loss: 0.9779, Accuracy: 32901/50000 (66%)\n",
      "Test set: Average loss: 1.0708, Accuracy: 6188/10000 (62%)\n",
      "Train set: Average loss: 0.9773, Accuracy: 32920/50000 (66%)\n",
      "Test set: Average loss: 1.0666, Accuracy: 6226/10000 (62%)\n",
      "Train set: Average loss: 0.9763, Accuracy: 32916/50000 (66%)\n",
      "Test set: Average loss: 1.0703, Accuracy: 6164/10000 (62%)\n",
      "Train set: Average loss: 0.9755, Accuracy: 32928/50000 (66%)\n",
      "Test set: Average loss: 1.0621, Accuracy: 6241/10000 (62%)\n",
      "Train set: Average loss: 0.9758, Accuracy: 32903/50000 (66%)\n",
      "Test set: Average loss: 1.0682, Accuracy: 6231/10000 (62%)\n",
      "Train set: Average loss: 0.9751, Accuracy: 32977/50000 (66%)\n",
      "Test set: Average loss: 1.0648, Accuracy: 6213/10000 (62%)\n",
      "Train set: Average loss: 0.9741, Accuracy: 32970/50000 (66%)\n",
      "Test set: Average loss: 1.0750, Accuracy: 6172/10000 (62%)\n",
      "Train set: Average loss: 0.9716, Accuracy: 32963/50000 (66%)\n",
      "Test set: Average loss: 1.0663, Accuracy: 6215/10000 (62%)\n",
      "Train set: Average loss: 0.9724, Accuracy: 32999/50000 (66%)\n",
      "Test set: Average loss: 1.0628, Accuracy: 6210/10000 (62%)\n",
      "Train set: Average loss: 0.9707, Accuracy: 33043/50000 (66%)\n",
      "Test set: Average loss: 1.0881, Accuracy: 6128/10000 (61%)\n",
      "Train set: Average loss: 0.9697, Accuracy: 33033/50000 (66%)\n",
      "Test set: Average loss: 1.0763, Accuracy: 6147/10000 (61%)\n",
      "Train set: Average loss: 0.9701, Accuracy: 32976/50000 (66%)\n",
      "Test set: Average loss: 1.0622, Accuracy: 6246/10000 (62%)\n",
      "Train set: Average loss: 0.9681, Accuracy: 33041/50000 (66%)\n",
      "Test set: Average loss: 1.0603, Accuracy: 6239/10000 (62%)\n",
      "Train set: Average loss: 0.9676, Accuracy: 33109/50000 (66%)\n",
      "Test set: Average loss: 1.0645, Accuracy: 6215/10000 (62%)\n",
      "Train set: Average loss: 0.9670, Accuracy: 33133/50000 (66%)\n",
      "Test set: Average loss: 1.0620, Accuracy: 6250/10000 (62%)\n",
      "Train set: Average loss: 0.9675, Accuracy: 33084/50000 (66%)\n",
      "Test set: Average loss: 1.0600, Accuracy: 6254/10000 (63%)\n",
      "Train set: Average loss: 0.9658, Accuracy: 33119/50000 (66%)\n",
      "Test set: Average loss: 1.0676, Accuracy: 6232/10000 (62%)\n",
      "Train set: Average loss: 0.9654, Accuracy: 33131/50000 (66%)\n",
      "Test set: Average loss: 1.0692, Accuracy: 6216/10000 (62%)\n",
      "Train set: Average loss: 0.9662, Accuracy: 33179/50000 (66%)\n",
      "Test set: Average loss: 1.0757, Accuracy: 6217/10000 (62%)\n",
      "Train set: Average loss: 0.9659, Accuracy: 33110/50000 (66%)\n",
      "Test set: Average loss: 1.0649, Accuracy: 6213/10000 (62%)\n",
      "Train set: Average loss: 0.9634, Accuracy: 33173/50000 (66%)\n",
      "Test set: Average loss: 1.0562, Accuracy: 6261/10000 (63%)\n",
      "Train set: Average loss: 0.9627, Accuracy: 33191/50000 (66%)\n",
      "Test set: Average loss: 1.0612, Accuracy: 6219/10000 (62%)\n",
      "Train set: Average loss: 0.9615, Accuracy: 33174/50000 (66%)\n",
      "Test set: Average loss: 1.0596, Accuracy: 6249/10000 (62%)\n",
      "Train set: Average loss: 0.9605, Accuracy: 33261/50000 (67%)\n",
      "Test set: Average loss: 1.0584, Accuracy: 6255/10000 (63%)\n",
      "Train set: Average loss: 0.9617, Accuracy: 33228/50000 (66%)\n",
      "Test set: Average loss: 1.0617, Accuracy: 6279/10000 (63%)\n",
      "Train set: Average loss: 0.9601, Accuracy: 33206/50000 (66%)\n",
      "Test set: Average loss: 1.0765, Accuracy: 6204/10000 (62%)\n",
      "Train set: Average loss: 0.9601, Accuracy: 33152/50000 (66%)\n",
      "Test set: Average loss: 1.0675, Accuracy: 6237/10000 (62%)\n",
      "Train set: Average loss: 0.9592, Accuracy: 33243/50000 (66%)\n",
      "Test set: Average loss: 1.0548, Accuracy: 6248/10000 (62%)\n",
      "Train set: Average loss: 0.9578, Accuracy: 33273/50000 (67%)\n",
      "Test set: Average loss: 1.0559, Accuracy: 6271/10000 (63%)\n",
      "Train set: Average loss: 0.9573, Accuracy: 33305/50000 (67%)\n",
      "Test set: Average loss: 1.0910, Accuracy: 6176/10000 (62%)\n",
      "Train set: Average loss: 0.9575, Accuracy: 33310/50000 (67%)\n",
      "Test set: Average loss: 1.0634, Accuracy: 6253/10000 (63%)\n",
      "Train set: Average loss: 0.9558, Accuracy: 33225/50000 (66%)\n",
      "Test set: Average loss: 1.0513, Accuracy: 6302/10000 (63%)\n",
      "Train set: Average loss: 0.9550, Accuracy: 33312/50000 (67%)\n",
      "Test set: Average loss: 1.0504, Accuracy: 6273/10000 (63%)\n",
      "Train set: Average loss: 0.9548, Accuracy: 33346/50000 (67%)\n",
      "Test set: Average loss: 1.0540, Accuracy: 6276/10000 (63%)\n",
      "Train set: Average loss: 0.9559, Accuracy: 33349/50000 (67%)\n",
      "Test set: Average loss: 1.0539, Accuracy: 6266/10000 (63%)\n",
      "Train set: Average loss: 0.9545, Accuracy: 33310/50000 (67%)\n",
      "Test set: Average loss: 1.0552, Accuracy: 6280/10000 (63%)\n",
      "Train set: Average loss: 0.9542, Accuracy: 33378/50000 (67%)\n",
      "Test set: Average loss: 1.0556, Accuracy: 6320/10000 (63%)\n",
      "Train set: Average loss: 0.9517, Accuracy: 33337/50000 (67%)\n",
      "Test set: Average loss: 1.0618, Accuracy: 6308/10000 (63%)\n",
      "Train set: Average loss: 0.9505, Accuracy: 33396/50000 (67%)\n",
      "Test set: Average loss: 1.0471, Accuracy: 6304/10000 (63%)\n",
      "Train set: Average loss: 0.9515, Accuracy: 33490/50000 (67%)\n",
      "Test set: Average loss: 1.0629, Accuracy: 6229/10000 (62%)\n",
      "Train set: Average loss: 0.9515, Accuracy: 33320/50000 (67%)\n",
      "Test set: Average loss: 1.0527, Accuracy: 6249/10000 (62%)\n",
      "Train set: Average loss: 0.9502, Accuracy: 33453/50000 (67%)\n",
      "Test set: Average loss: 1.0517, Accuracy: 6290/10000 (63%)\n",
      "Train set: Average loss: 0.9492, Accuracy: 33439/50000 (67%)\n",
      "Test set: Average loss: 1.0549, Accuracy: 6290/10000 (63%)\n",
      "Train set: Average loss: 0.9490, Accuracy: 33391/50000 (67%)\n",
      "Test set: Average loss: 1.0639, Accuracy: 6243/10000 (62%)\n",
      "Train set: Average loss: 0.9496, Accuracy: 33433/50000 (67%)\n",
      "Test set: Average loss: 1.0459, Accuracy: 6303/10000 (63%)\n",
      "Train set: Average loss: 0.9465, Accuracy: 33560/50000 (67%)\n",
      "Test set: Average loss: 1.0677, Accuracy: 6229/10000 (62%)\n",
      "Train set: Average loss: 0.9467, Accuracy: 33449/50000 (67%)\n",
      "Test set: Average loss: 1.0491, Accuracy: 6308/10000 (63%)\n",
      "Train set: Average loss: 0.9446, Accuracy: 33446/50000 (67%)\n",
      "Test set: Average loss: 1.0512, Accuracy: 6327/10000 (63%)\n",
      "Train set: Average loss: 0.9451, Accuracy: 33493/50000 (67%)\n",
      "Test set: Average loss: 1.0587, Accuracy: 6273/10000 (63%)\n",
      "Train set: Average loss: 0.9457, Accuracy: 33508/50000 (67%)\n",
      "Test set: Average loss: 1.0511, Accuracy: 6323/10000 (63%)\n",
      "Train set: Average loss: 0.9446, Accuracy: 33488/50000 (67%)\n",
      "Test set: Average loss: 1.0501, Accuracy: 6296/10000 (63%)\n",
      "Train set: Average loss: 0.9439, Accuracy: 33555/50000 (67%)\n",
      "Test set: Average loss: 1.0575, Accuracy: 6259/10000 (63%)\n",
      "Train set: Average loss: 0.9429, Accuracy: 33503/50000 (67%)\n",
      "Test set: Average loss: 1.0452, Accuracy: 6314/10000 (63%)\n",
      "Train set: Average loss: 0.9414, Accuracy: 33565/50000 (67%)\n",
      "Test set: Average loss: 1.0444, Accuracy: 6317/10000 (63%)\n",
      "Train set: Average loss: 0.9416, Accuracy: 33492/50000 (67%)\n",
      "Test set: Average loss: 1.0522, Accuracy: 6265/10000 (63%)\n",
      "Train set: Average loss: 0.9419, Accuracy: 33564/50000 (67%)\n",
      "Test set: Average loss: 1.0419, Accuracy: 6316/10000 (63%)\n",
      "Train set: Average loss: 0.9395, Accuracy: 33617/50000 (67%)\n",
      "Test set: Average loss: 1.0472, Accuracy: 6314/10000 (63%)\n",
      "Train set: Average loss: 0.9389, Accuracy: 33634/50000 (67%)\n",
      "Test set: Average loss: 1.0573, Accuracy: 6283/10000 (63%)\n",
      "Train set: Average loss: 0.9379, Accuracy: 33628/50000 (67%)\n",
      "Test set: Average loss: 1.0580, Accuracy: 6266/10000 (63%)\n",
      "Train set: Average loss: 0.9380, Accuracy: 33565/50000 (67%)\n",
      "Test set: Average loss: 1.0646, Accuracy: 6244/10000 (62%)\n",
      "Train set: Average loss: 0.9377, Accuracy: 33634/50000 (67%)\n",
      "Test set: Average loss: 1.0442, Accuracy: 6320/10000 (63%)\n",
      "Train set: Average loss: 0.9370, Accuracy: 33687/50000 (67%)\n",
      "Test set: Average loss: 1.0457, Accuracy: 6328/10000 (63%)\n",
      "Train set: Average loss: 0.9378, Accuracy: 33619/50000 (67%)\n",
      "Test set: Average loss: 1.0543, Accuracy: 6283/10000 (63%)\n",
      "Train set: Average loss: 0.9360, Accuracy: 33676/50000 (67%)\n",
      "Test set: Average loss: 1.0397, Accuracy: 6321/10000 (63%)\n",
      "Train set: Average loss: 0.9368, Accuracy: 33633/50000 (67%)\n",
      "Test set: Average loss: 1.0490, Accuracy: 6375/10000 (64%)\n",
      "Train set: Average loss: 0.9360, Accuracy: 33723/50000 (67%)\n",
      "Test set: Average loss: 1.0458, Accuracy: 6324/10000 (63%)\n",
      "Train set: Average loss: 0.9337, Accuracy: 33747/50000 (67%)\n",
      "Test set: Average loss: 1.0415, Accuracy: 6339/10000 (63%)\n",
      "Train set: Average loss: 0.9351, Accuracy: 33640/50000 (67%)\n",
      "Test set: Average loss: 1.0451, Accuracy: 6325/10000 (63%)\n",
      "Train set: Average loss: 0.9344, Accuracy: 33709/50000 (67%)\n",
      "Test set: Average loss: 1.0496, Accuracy: 6309/10000 (63%)\n",
      "Train set: Average loss: 0.9327, Accuracy: 33761/50000 (68%)\n",
      "Test set: Average loss: 1.0692, Accuracy: 6249/10000 (62%)\n",
      "Train set: Average loss: 0.9305, Accuracy: 33767/50000 (68%)\n",
      "Test set: Average loss: 1.0438, Accuracy: 6295/10000 (63%)\n",
      "Train set: Average loss: 0.9303, Accuracy: 33773/50000 (68%)\n",
      "Test set: Average loss: 1.0381, Accuracy: 6329/10000 (63%)\n",
      "Train set: Average loss: 0.9302, Accuracy: 33836/50000 (68%)\n",
      "Test set: Average loss: 1.0450, Accuracy: 6328/10000 (63%)\n",
      "Train set: Average loss: 0.9305, Accuracy: 33832/50000 (68%)\n",
      "Test set: Average loss: 1.0437, Accuracy: 6357/10000 (64%)\n",
      "Train set: Average loss: 0.9291, Accuracy: 33847/50000 (68%)\n",
      "Test set: Average loss: 1.0380, Accuracy: 6374/10000 (64%)\n",
      "Train set: Average loss: 0.9283, Accuracy: 33861/50000 (68%)\n",
      "Test set: Average loss: 1.0441, Accuracy: 6346/10000 (63%)\n",
      "Train set: Average loss: 0.9284, Accuracy: 33771/50000 (68%)\n",
      "Test set: Average loss: 1.0553, Accuracy: 6290/10000 (63%)\n",
      "Train set: Average loss: 0.9272, Accuracy: 33839/50000 (68%)\n",
      "Test set: Average loss: 1.0385, Accuracy: 6353/10000 (64%)\n",
      "Train set: Average loss: 0.9274, Accuracy: 33843/50000 (68%)\n",
      "Test set: Average loss: 1.0429, Accuracy: 6352/10000 (64%)\n",
      "Train set: Average loss: 0.9264, Accuracy: 33806/50000 (68%)\n",
      "Test set: Average loss: 1.0449, Accuracy: 6316/10000 (63%)\n",
      "Train set: Average loss: 0.9269, Accuracy: 33809/50000 (68%)\n",
      "Test set: Average loss: 1.0431, Accuracy: 6331/10000 (63%)\n",
      "Train set: Average loss: 0.9271, Accuracy: 33821/50000 (68%)\n",
      "Test set: Average loss: 1.0404, Accuracy: 6339/10000 (63%)\n",
      "Train set: Average loss: 0.9235, Accuracy: 33903/50000 (68%)\n",
      "Test set: Average loss: 1.0353, Accuracy: 6359/10000 (64%)\n",
      "Train set: Average loss: 0.9243, Accuracy: 33920/50000 (68%)\n",
      "Test set: Average loss: 1.0405, Accuracy: 6349/10000 (63%)\n",
      "Train set: Average loss: 0.9256, Accuracy: 33812/50000 (68%)\n",
      "Test set: Average loss: 1.0445, Accuracy: 6354/10000 (64%)\n",
      "Train set: Average loss: 0.9226, Accuracy: 33938/50000 (68%)\n",
      "Test set: Average loss: 1.0360, Accuracy: 6358/10000 (64%)\n",
      "Train set: Average loss: 0.9229, Accuracy: 33864/50000 (68%)\n",
      "Test set: Average loss: 1.0377, Accuracy: 6372/10000 (64%)\n",
      "Train set: Average loss: 0.9229, Accuracy: 33962/50000 (68%)\n",
      "Test set: Average loss: 1.0487, Accuracy: 6337/10000 (63%)\n",
      "Train set: Average loss: 0.9238, Accuracy: 33893/50000 (68%)\n",
      "Test set: Average loss: 1.0408, Accuracy: 6367/10000 (64%)\n",
      "Train set: Average loss: 0.9207, Accuracy: 33900/50000 (68%)\n",
      "Test set: Average loss: 1.0508, Accuracy: 6268/10000 (63%)\n",
      "Train set: Average loss: 0.9210, Accuracy: 33926/50000 (68%)\n",
      "Test set: Average loss: 1.0412, Accuracy: 6349/10000 (63%)\n",
      "Train set: Average loss: 0.9195, Accuracy: 33959/50000 (68%)\n",
      "Test set: Average loss: 1.0375, Accuracy: 6360/10000 (64%)\n",
      "Train set: Average loss: 0.9204, Accuracy: 33962/50000 (68%)\n",
      "Test set: Average loss: 1.0473, Accuracy: 6327/10000 (63%)\n",
      "Train set: Average loss: 0.9202, Accuracy: 33896/50000 (68%)\n",
      "Test set: Average loss: 1.0333, Accuracy: 6347/10000 (63%)\n",
      "Train set: Average loss: 0.9194, Accuracy: 33957/50000 (68%)\n",
      "Test set: Average loss: 1.0457, Accuracy: 6324/10000 (63%)\n",
      "Train set: Average loss: 0.9176, Accuracy: 33970/50000 (68%)\n",
      "Test set: Average loss: 1.0337, Accuracy: 6368/10000 (64%)\n",
      "Train set: Average loss: 0.9176, Accuracy: 34011/50000 (68%)\n",
      "Test set: Average loss: 1.0402, Accuracy: 6325/10000 (63%)\n",
      "Train set: Average loss: 0.9162, Accuracy: 34017/50000 (68%)\n",
      "Test set: Average loss: 1.0358, Accuracy: 6350/10000 (64%)\n",
      "Train set: Average loss: 0.9149, Accuracy: 34059/50000 (68%)\n",
      "Test set: Average loss: 1.0424, Accuracy: 6361/10000 (64%)\n",
      "Train set: Average loss: 0.9153, Accuracy: 34069/50000 (68%)\n",
      "Test set: Average loss: 1.0461, Accuracy: 6361/10000 (64%)\n",
      "Train set: Average loss: 0.9156, Accuracy: 34044/50000 (68%)\n",
      "Test set: Average loss: 1.0286, Accuracy: 6403/10000 (64%)\n",
      "Train set: Average loss: 0.9160, Accuracy: 34008/50000 (68%)\n",
      "Test set: Average loss: 1.0450, Accuracy: 6324/10000 (63%)\n",
      "Train set: Average loss: 0.9130, Accuracy: 34066/50000 (68%)\n",
      "Test set: Average loss: 1.0333, Accuracy: 6381/10000 (64%)\n",
      "Train set: Average loss: 0.9120, Accuracy: 34102/50000 (68%)\n",
      "Test set: Average loss: 1.0322, Accuracy: 6375/10000 (64%)\n",
      "Train set: Average loss: 0.9136, Accuracy: 34011/50000 (68%)\n",
      "Test set: Average loss: 1.0300, Accuracy: 6380/10000 (64%)\n",
      "Train set: Average loss: 0.9111, Accuracy: 34110/50000 (68%)\n",
      "Test set: Average loss: 1.0394, Accuracy: 6353/10000 (64%)\n",
      "Train set: Average loss: 0.9121, Accuracy: 34174/50000 (68%)\n",
      "Test set: Average loss: 1.0375, Accuracy: 6342/10000 (63%)\n",
      "Train set: Average loss: 0.9122, Accuracy: 34103/50000 (68%)\n",
      "Test set: Average loss: 1.0316, Accuracy: 6343/10000 (63%)\n",
      "Train set: Average loss: 0.9120, Accuracy: 34124/50000 (68%)\n",
      "Test set: Average loss: 1.0441, Accuracy: 6353/10000 (64%)\n",
      "Train set: Average loss: 0.9104, Accuracy: 34086/50000 (68%)\n",
      "Test set: Average loss: 1.0452, Accuracy: 6327/10000 (63%)\n",
      "Train set: Average loss: 0.9100, Accuracy: 34165/50000 (68%)\n",
      "Test set: Average loss: 1.0467, Accuracy: 6341/10000 (63%)\n",
      "Train set: Average loss: 0.9098, Accuracy: 34101/50000 (68%)\n",
      "Test set: Average loss: 1.0381, Accuracy: 6334/10000 (63%)\n",
      "Train set: Average loss: 0.9084, Accuracy: 34207/50000 (68%)\n",
      "Test set: Average loss: 1.0327, Accuracy: 6371/10000 (64%)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    train(model, device, federated_train_loader, optimizer, epoch, batch_size=200)\n",
    "    test(model, device, federated_test_loader, batch_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7G3zJ6GbECg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 结果保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HEX35umZbECg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save_name='LeNet-no-fed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "0Aoix93zbECh",
    "outputId": "e55f913b-8fbb-4ff6-bb17-a625f9059dd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存文件： /home/zhaojia-raoxy/model/out/LeNet-no-fed.pt\n"
     ]
    }
   ],
   "source": [
    "# 保存模型的权重\n",
    "torch.save(model.state_dict(), \"/home/zhaojia-raoxy/model/out/{}.pt\".format(save_name))\n",
    "print(\"保存文件：\",\"/home/zhaojia-raoxy/model/out/{}.pt\".format(save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "P01ivKSibECh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存文件： /home/zhaojia-raoxy/model/out/LeNet-no-fed.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhaojia-raoxy/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type LeNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# 保存整个模型\n",
    "torch.save(model, \"/home/zhaojia-raoxy/model/out/{}.h5\".format(save_name))\n",
    "print(\"保存文件：\",\"/home/zhaojia-raoxy/model/out/{}.h5\".format(save_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FeuT1YzKbECi"
   },
   "source": [
    "# 分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame([loss_train, loss_test, acc_train, acc_test]).T\n",
    "df.columns =['loss_train', 'loss_test','acc_train','acc_test']\n",
    "df.to_csv(\"/home/zhaojia-raoxy/files/{}\".format(save_name),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mpl.use('svg')\n",
    "mpl.style.use('seaborn-white')\n",
    "\n",
    "# 将DataFrame中的数据进行可视化，设置两个y轴\n",
    "ax = df[['loss_train', 'loss_test']].plot(color=['#CD0056','#F47EAB'])\n",
    "# 创建一个新的Axes对象，共享x轴\n",
    "ax2 = ax.twinx()\n",
    "# 绘制'acc_train'和'acc_test'在右侧y轴\n",
    "df[['acc_train', 'acc_test']].plot(ax=ax2, color=['#0C755F', '#A2C69B'])\n",
    "# 设置左侧y轴标签\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('epoch')\n",
    "# 设置右侧y轴标签\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax.grid(True)\n",
    "ax2.grid(True)\n",
    "\n",
    "# 显示图形\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "DEpaqaspbECi",
    "outputId": "67858a14-05f2-460d-b534-691fce3fc414"
   },
   "outputs": [],
   "source": [
    "# def plotP(test_loss, train_loss, train_acc_list, test_acc_list):\n",
    "#     plt.figure(figsize=(6, 8))\n",
    "    \n",
    "#     x = list(range(len(train_loss)))\n",
    "#     y = list(range(len(test_acc_list)))\n",
    "    \n",
    "#     plt.subplot(2, 1, 1)\n",
    "#     plt.plot(x, train_loss, label=\"train_loss\")\n",
    "#     plt.plot(x, test_loss, label=\"test_loss\")\n",
    "\n",
    "#     plt.xlabel(\"epoch\")\n",
    "#     plt.ylabel(\"loss\")\n",
    "#     plt.legend()\n",
    "#     plt.subplot(2, 1, 2)\n",
    "#     plt.plot(y, train_acc_list, label=\"train_acc\")\n",
    "#     plt.plot(y, test_acc_list, label=\"test_acc\")\n",
    "#     plt.xlabel(\"epoch\")\n",
    "#     plt.ylabel(\"acc\")\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "# plotP(loss_test,loss_train, acc_train, acc_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:pysyft]",
   "language": "python",
   "name": "conda-env-pysyft-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "785px",
    "left": "120px",
    "top": "110.525px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
