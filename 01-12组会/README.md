# 工作安排：实验

- [ ] 复现：Auditing Privacy Defenses in Federated Learning via Generative Gradient Leakage

> [⁡⁤‍‌﻿⁣⁢⁡⁢﻿⁡⁣﻿⁢⁣⁢⁣⁣﻿⁣﻿⁣⁢‍⁤⁡‌⁡‬﻿⁢⁢⁢⁤⁡⁡‌⁡‬⁤Auditing Privacy Defenses in Federated Learning via Generative Gradient Leakage - 飞书云文档 (feishu.cn)](https://z1q7kn87r2y.feishu.cn/docx/D9Z0d1nEFo5nBlxwznxcOXjBnZg)

- [ ] 复现：GradViT: Gradient Inversion of Vision Transformers

>  [⁣⁣⁣⁣⁤‍⁡⁣‍‍⁢﻿‌⁣‬⁤‬﻿‌‌⁣﻿⁢‌⁡‬⁣⁣‬﻿‬⁡‌‌﻿‌⁡⁤‌⁢‌GradViT: Gradient Inversion of Vision Transformers - 飞书云文档 (feishu.cn)](https://z1q7kn87r2y.feishu.cn/docx/SKwudqmSUoJXlBxcveWcRMANn8d)

- [ ] 复现：Using Highly Compressed Gradients in Federated Learning for Data Reconstruction Attacks

> [HCGLA(2022 ) - 飞书云文档 (feishu.cn)](https://z1q7kn87r2y.feishu.cn/docx/MDAWdmtUtomoS0xH4aHcWDFfnPe)

- [ ] 复现：Dreaming to Distill: Data-free Knowledge Transfer via DeepInversion

> [‍⁢⁡‌‌‌‍⁤⁤‌‌‬‬⁢‌⁡‬⁤‬﻿⁡⁤‬⁤‍⁤‌‍⁢⁤⁢‬‌‍⁣⁤‬⁤⁤Dreaming to Distill: Data-free Knowledge Transfer via DeepInversion（CVPR 2020） - 飞书云文档 (feishu.cn)](https://z1q7kn87r2y.feishu.cn/docx/QCX3dRIytoC8QXxTqRHc1NPQnib)

## GradInversion

- [x] 复现：See through Gradients: Image Batch Recovery via GradInversion

> [‌⁢‍⁡⁡‬⁤‬‌⁣﻿﻿‍⁢⁤‍‌‍‌‍﻿⁢‍‬‍⁤‌⁤⁢⁢⁤‌⁢⁢‬⁡‬⁣‬⁢⁣‍GradInversion（CVPR 2021 ） - 飞书云文档 (feishu.cn)](https://z1q7kn87r2y.feishu.cn/docx/Cb1Ed5tEUom4WyxebLrcVEuDn4c)

[See through Gradients - Optimization-based Attack - ResNet50 on ImageNet - Jupyter Notebook](http://59.65.191.29:8888/notebooks/breaching-main/examples/See through Gradients - Optimization-based Attack - ResNet50 on ImageNet.ipynb)

[Iov-with-FL/12-22组会/See through Gradients - Optimization-based Attack - ResNet50 on ImageNet.ipynb at main · lao1a0/Iov-with-FL (github.com)](https://github.com/lao1a0/Iov-with-FL/blob/main/12-22组会/See through Gradients - Optimization-based Attack - ResNet50 on ImageNet.ipynb)

## Inverting Gradients

- [x] 复现：Inverting Gradients -- How easy is it to break privacy in federated learning?

> [‍‌‌‍⁤⁤⁢‬⁡⁡⁣⁣⁣⁣‌﻿⁢⁡⁣⁤‍⁡‍‬⁡‬⁢⁢⁡‌⁤⁢‍﻿‌‬‬⁤⁡‬⁤Inverting gradients - 飞书云文档 (feishu.cn)](https://z1q7kn87r2y.feishu.cn/docx/G7uTdmbByo62R2xeUsMcEl8Rnxc)

代码：

[Inverting Gradients - Optimization-based Attack - Large Batch CIFAR-100 - Jupyter Notebook](http://59.65.191.29:8888/notebooks/breaching-main/examples/Inverting Gradients - Optimization-based Attack - Large Batch CIFAR-100.ipynb)

[Inverting Gradients - Optimization-based Attack - ResNet18 on ImageNet - Federated Averaging - Jupyter Notebook](http://59.65.191.29:8888/notebooks/breaching-main/examples/Inverting Gradients - Optimization-based Attack - ResNet18 on ImageNet - Federated Averaging.ipynb)

[Inverting Gradients - Optimization-based Attack - ResNet18 on ImageNet - Jupyter Notebook](http://59.65.191.29:8888/notebooks/breaching-main/examples/Inverting Gradients - Optimization-based Attack - ResNet18 on ImageNet.ipynb)

## iDLG

- [x] 复现：iDLG: Improved Deep Leakage from Gradients

> [⁣⁣‬⁡⁤﻿⁣⁣⁤⁡‍⁢‬⁤‌‌﻿⁣‍⁡‬‌⁤‍﻿⁤﻿‬⁣⁡⁢⁣⁣⁢‌﻿‬⁣⁣‬‍⁤⁣iDLG - 飞书云文档 (feishu.cn)](https://z1q7kn87r2y.feishu.cn/docx/MseNdO89PoybxbxUdwJcdOAUnOc)

[Iov-with-FL/12-15组会 at main · lao1a0/Iov-with-FL (github.com)](https://github.com/lao1a0/Iov-with-FL/tree/main/12-15组会)

## DLG

- [x] 复现：Deep Leakage from Gradients

> [‌‍⁣‍⁢⁣﻿‌⁡⁣‬⁤﻿﻿⁢⁣⁣⁣‍‌‍‍⁢⁤‬﻿‌⁢‍‌⁤⁡⁡‌⁣⁣‬⁣DLG（NeurIPS 2019） - 飞书云文档 (feishu.cn)](https://z1q7kn87r2y.feishu.cn/docx/Zv5YdoirZoiPRuxzTg4clejqnog)

[Deep Leakage from Gradients - Optimization-based Attack - ConvNet CIFAR-10 - Jupyter Notebook](http://59.65.191.29:8888/notebooks/breaching-main/examples/Deep Leakage from Gradients - Optimization-based Attack - ConvNet CIFAR-10.ipynb)

# 工作安排：论文

- [ ] 写完第2章
- [ ] 写完研究现状
- [ ] 看完5篇硕士论文

