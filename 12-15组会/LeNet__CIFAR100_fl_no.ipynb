{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\syftpy\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\Anaconda\\envs\\syftpy\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "D:\\Anaconda\\envs\\syftpy\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import syft as sy\n",
    "# import copy\n",
    "# hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a couple workers\n",
    "# bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "# alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "# secure_worker_a = sy.VirtualWorker(hook, id=\"secure_worker_a\")\n",
    "# secure_worker_b = sy.VirtualWorker(hook, id=\"secure_worker_b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "train_transforms = transforms.Compose([#transforms.RandomRotation(30),\n",
    "                                       # transforms.RandomResizedCrop(224),\n",
    "                                       # transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.5,], [0.5,])]) # mean, std\n",
    " \n",
    "\n",
    "test_transforms = transforms.Compose([#transforms.Resize(255),\n",
    "                                      #transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.5,], [0.5,])]) # mean, std\n",
    "\n",
    "\n",
    "# choose the training and test datasets\n",
    "\n",
    "# federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
    "#     datasets.CIFAR100('/home/zhaojia-raoxy/data', train=True, download=True,\n",
    "#                    transform=train_transforms)\n",
    "#     .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "#     batch_size=20, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "# federated_test_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
    "#     datasets.CIFAR100('/home/zhaojia-raoxy/data', train=False, download=True,\n",
    "#                    transform=test_transforms)\n",
    "#     .federate((secure_worker_a, secure_worker_b)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "#     batch_size=20, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "federated_train_loader = torch.utils.data.DataLoader( # <-- this is now a FederatedDataLoader \n",
    "    datasets.CIFAR100('/home/zhaojia-raoxy/data', train=True, download=True,\n",
    "                   transform=train_transforms), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "    batch_size=20, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "federated_test_loader = torch.utils.data.DataLoader( # <-- this is now a FederatedDataLoader \n",
    "    datasets.CIFAR100('/home/zhaojia-raoxy/data', train=False, download=True,\n",
    "                   transform=test_transforms), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "    batch_size=20, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型\n",
    "## LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, channel=3, hideen=768, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        act = nn.Sigmoid\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channel, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=1),\n",
    "            act(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hideen, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "model = LeNet(channel=3, hideen=768, num_classes=100).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.03) # TODO momentum is not supported at the moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN(nn.Module):\n",
    "#     def __init__(self, num_class):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.block1 = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5),\n",
    "#             nn.ReLU(),\n",
    "#             nn.AdaptiveAvgPool2d(5),\n",
    "#             nn.Dropout(p=0.5)\n",
    "\n",
    "#         )\n",
    "#         self.block2 = nn.Sequential(\n",
    "#             nn.Conv2d(64, 32, 5, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2),\n",
    "#         )\n",
    "#         self.block3 = nn.Sequential(\n",
    "#             nn.Linear(32, num_class),\n",
    "#             nn.LogSoftmax(dim=1)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.block1(x)\n",
    "#         x = self.block2(x)\n",
    "#         x = x.view(x.shape[0], -1)  # torch.Size([128, 32])\n",
    "#         x = self.block3(x)\n",
    "#         return x\n",
    "    \n",
    "# model = CNN(100).to(device)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.03) # TODO momentum is not supported at the moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Arguments():\n",
    "#     def __init__(self):\n",
    "#         self.batch_size = 128\n",
    "#         self.epochs = 50\n",
    "#         self.lr = 0.02\n",
    "#         self.num_class = 5\n",
    "#         self.save_name = 'yeo_alexnet_lr0.01_epoch50'\n",
    "#         self.data_train = '/home/raoxy/data/train_yeo'\n",
    "#         self.data_test = '/home/raoxy/data/test_yeo'\n",
    "#         self.model_name = '/home/raoxy/model/resnet18-5c106cde.pth'\n",
    "#         self.save_name = 'yeo_resnet18_lr0.01_epoch50'\n",
    "\n",
    "# args = Arguments()\n",
    "\n",
    "# def ResNet_s(args):\n",
    "#     ''':cvar\n",
    "#     返回修改好的模型，和冻结好的参数\n",
    "#     '''\n",
    "#     from torchvision.models import resnet18, resnet34, resnet50, resnet101, resnet152  # ResNet系列\n",
    "#     pretrain_model = resnet18(pretrained=False)\n",
    "#     pretrain_model.fc = nn.Linear(pretrain_model.fc.in_features, 100)  # 将全连接层改为自己想要的分类输出\n",
    "#     pretrained_dict = torch.load(args.model_name)\n",
    "\n",
    "#     pretrained_dict.pop('fc.weight')\n",
    "#     pretrained_dict.pop('fc.bias')\n",
    "\n",
    "#     model_dict = pretrain_model.state_dict()\n",
    "#     pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "\n",
    "#     model_dict.update(pretrained_dict)  # 模型参数列表进行参数更新，加载参数\n",
    "#     pretrain_model.load_state_dict(model_dict)  # 将满足条件的参数的 requires_grad 属性设置为False\n",
    "\n",
    "# #     for name, value in pretrain_model.named_parameters():\n",
    "# #         if (name != 'fc.weight') and (name != 'fc.bias'):\n",
    "# #             value.requires_grad = False\n",
    "#     params_conv = filter(lambda p: p.requires_grad, pretrain_model.parameters())  # 要更新的参数在parms_conv当中\n",
    "#     return pretrain_model, params_conv\n",
    "\n",
    "# model, params_conv = ResNet_s(args)\n",
    "# optimizer = optim.SGD(params_conv, lr=0.03) # TODO momentum is not supported at the moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "loss_train=[]\n",
    "acc_train=[]\n",
    "loss2=[]\n",
    "\n",
    "def train(model, device, federated_train_loader, optimizer, epoch, batch_size):\n",
    "    global criterion\n",
    "    model.train()\n",
    "   \n",
    "    for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
    "#         model.send(data.location) # <-- NEW: send the model to the right location\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target.long())\n",
    "#         loss = F.cross_entropy(output, target.long())\n",
    "#         loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         model.get() # <-- NEW: get the model back\n",
    "        \n",
    "        if batch_idx % 2000 == 0:\n",
    "#             loss = loss.get() # <-- NEW: get the loss\n",
    "            # loss_train.append(loss.item())\n",
    "            # acc_train.append()\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * batch_size, len(federated_train_loader) * batch_size,\n",
    "                100. * batch_idx / len(federated_train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, federated_test_loader, batch_size): \n",
    "    global criterion\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in federated_test_loader:\n",
    "#             model.send(data.location) # <-- NEW: send the model in virtual workers to Trusted Aggregator\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target.long())\n",
    "#             loss = F.nll_loss(output, target, reduction='sum')\n",
    "#             model.get()\n",
    "#             test_loss += loss.get() # sum up batch loss\n",
    "            test_loss += loss.item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(federated_test_loader)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(federated_test_loader) * batch_size,\n",
    "        100. * correct / len(federated_test_loader) / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 4.594889\n",
      "Train Epoch: 0 [40000/50000 (80%)]\tLoss: 4.612164\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32mD:\\Temp\\ipykernel_18720\\585417084.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m50\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m     \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfederated_train_loader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m20\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m     \u001B[0mtest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfederated_test_loader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m20\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mD:\\Temp\\ipykernel_18720\\3688804435.py\u001B[0m in \u001B[0;36mtest\u001B[1;34m(model, device, federated_test_loader, batch_size)\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mcorrect\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m         \u001B[1;32mfor\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mfederated_test_loader\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;31m#             model.send(data.location) # <-- NEW: send the model in virtual workers to Trusted Aggregator\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m             \u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\syftpy\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    343\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    344\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__next__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 345\u001B[1;33m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    346\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    347\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\syftpy\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    828\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    829\u001B[0m                 \u001B[1;31m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 830\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_shutdown_workers\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    831\u001B[0m                 \u001B[1;32mraise\u001B[0m \u001B[0mStopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    832\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\syftpy\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_shutdown_workers\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    939\u001B[0m                         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_shutdown_worker\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mworker_id\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    940\u001B[0m                 \u001B[1;32mfor\u001B[0m \u001B[0mw\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_workers\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 941\u001B[1;33m                     \u001B[0mw\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    942\u001B[0m                 \u001B[1;32mfor\u001B[0m \u001B[0mq\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_index_queues\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    943\u001B[0m                     \u001B[0mq\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcancel_join_thread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\syftpy\\lib\\multiprocessing\\process.py\u001B[0m in \u001B[0;36mjoin\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    138\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_parent_pid\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgetpid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'can only join a child process'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    139\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_popen\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'can only join a started process'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 140\u001B[1;33m         \u001B[0mres\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_popen\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    141\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mres\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    142\u001B[0m             \u001B[0m_children\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdiscard\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\syftpy\\lib\\multiprocessing\\popen_spawn_win32.py\u001B[0m in \u001B[0;36mwait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    102\u001B[0m                 \u001B[0mmsecs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;36m1000\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m0.5\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 104\u001B[1;33m             \u001B[0mres\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_winapi\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mWaitForSingleObject\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_handle\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmsecs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    105\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mres\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0m_winapi\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mWAIT_OBJECT_0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    106\u001B[0m                 \u001B[0mcode\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_winapi\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mGetExitCodeProcess\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_handle\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    train(model, device, federated_train_loader, optimizer, epoch, batch_size=20)\n",
    "    test(model, device, federated_test_loader, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 结果保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save_name='LeNet-no-fed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型的权重\n",
    "torch.save(model.state_dict(), \"/home/zhaojia-raoxy/model/out/{}.pt\".format(save_name))\n",
    "print(\"保存文件：\",\"/home/zhaojia-raoxy/model/out/{}.pt\".format(save_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存整个模型\n",
    "torch.save(model, \"/home/zhaojia-raoxy/model/out/{}.h5\".format(save_name))\n",
    "print(\"保存文件：\",\"/home/zhaojia-raoxy/model/out/{}.h5\".format(save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt='''\n",
    "Train Epoch: 0 [0/50000 (0%)]\tLoss: 4.708676\n",
    "Train Epoch: 0 [40000/50000 (80%)]\tLoss: 4.590685\n",
    "\n",
    "Test set: Average loss: 4.6056, Accuracy: 95/10000 (1%)\n",
    "\n",
    "Train Epoch: 1 [0/50000 (0%)]\tLoss: 4.604600\n",
    "Train Epoch: 1 [40000/50000 (80%)]\tLoss: 4.602582\n",
    "\n",
    "Test set: Average loss: 4.6052, Accuracy: 100/10000 (1%)\n",
    "\n",
    "Train Epoch: 2 [0/50000 (0%)]\tLoss: 4.596632\n",
    "Train Epoch: 2 [40000/50000 (80%)]\tLoss: 4.611558\n",
    "\n",
    "Test set: Average loss: 4.6049, Accuracy: 100/10000 (1%)\n",
    "\n",
    "Train Epoch: 3 [0/50000 (0%)]\tLoss: 4.617929\n",
    "Train Epoch: 3 [40000/50000 (80%)]\tLoss: 4.607579\n",
    "\n",
    "Test set: Average loss: 4.6039, Accuracy: 96/10000 (1%)\n",
    "\n",
    "Train Epoch: 4 [0/50000 (0%)]\tLoss: 4.605203\n",
    "Train Epoch: 4 [40000/50000 (80%)]\tLoss: 4.605900\n",
    "\n",
    "Test set: Average loss: 4.5987, Accuracy: 102/10000 (1%)\n",
    "\n",
    "Train Epoch: 5 [0/50000 (0%)]\tLoss: 4.589950\n",
    "Train Epoch: 5 [40000/50000 (80%)]\tLoss: 4.492353\n",
    "\n",
    "Test set: Average loss: 4.4701, Accuracy: 342/10000 (3%)\n",
    "\n",
    "Train Epoch: 6 [0/50000 (0%)]\tLoss: 4.495493\n",
    "Train Epoch: 6 [40000/50000 (80%)]\tLoss: 3.969273\n",
    "\n",
    "Test set: Average loss: 4.2379, Accuracy: 572/10000 (6%)\n",
    "\n",
    "Train Epoch: 7 [0/50000 (0%)]\tLoss: 4.229941\n",
    "Train Epoch: 7 [40000/50000 (80%)]\tLoss: 4.037433\n",
    "\n",
    "Test set: Average loss: 4.0686, Accuracy: 781/10000 (8%)\n",
    "\n",
    "Train Epoch: 8 [0/50000 (0%)]\tLoss: 4.223968\n",
    "Train Epoch: 8 [40000/50000 (80%)]\tLoss: 4.097197\n",
    "\n",
    "Test set: Average loss: 3.9766, Accuracy: 988/10000 (10%)\n",
    "\n",
    "Train Epoch: 9 [0/50000 (0%)]\tLoss: 3.944783\n",
    "Train Epoch: 9 [40000/50000 (80%)]\tLoss: 3.951657\n",
    "\n",
    "Test set: Average loss: 3.8865, Accuracy: 1147/10000 (11%)\n",
    "\n",
    "Train Epoch: 10 [0/50000 (0%)]\tLoss: 4.041358\n",
    "Train Epoch: 10 [40000/50000 (80%)]\tLoss: 4.043406\n",
    "\n",
    "Test set: Average loss: 3.7876, Accuracy: 1301/10000 (13%)\n",
    "\n",
    "Train Epoch: 11 [0/50000 (0%)]\tLoss: 3.518500\n",
    "Train Epoch: 11 [40000/50000 (80%)]\tLoss: 3.735777\n",
    "\n",
    "Test set: Average loss: 3.6846, Accuracy: 1469/10000 (15%)\n",
    "\n",
    "Train Epoch: 12 [0/50000 (0%)]\tLoss: 3.699314\n",
    "Train Epoch: 12 [40000/50000 (80%)]\tLoss: 3.753798\n",
    "\n",
    "Test set: Average loss: 3.6119, Accuracy: 1626/10000 (16%)\n",
    "\n",
    "Train Epoch: 13 [0/50000 (0%)]\tLoss: 3.669033\n",
    "Train Epoch: 13 [40000/50000 (80%)]\tLoss: 3.134054\n",
    "\n",
    "Test set: Average loss: 3.5677, Accuracy: 1732/10000 (17%)\n",
    "\n",
    "Train Epoch: 14 [0/50000 (0%)]\tLoss: 2.734629\n",
    "Train Epoch: 14 [40000/50000 (80%)]\tLoss: 3.647416\n",
    "\n",
    "Test set: Average loss: 3.5019, Accuracy: 1819/10000 (18%)\n",
    "\n",
    "Train Epoch: 15 [0/50000 (0%)]\tLoss: 3.676202\n",
    "Train Epoch: 15 [40000/50000 (80%)]\tLoss: 3.568512\n",
    "\n",
    "Test set: Average loss: 3.4599, Accuracy: 1882/10000 (19%)\n",
    "\n",
    "Train Epoch: 16 [0/50000 (0%)]\tLoss: 3.509736\n",
    "Train Epoch: 16 [40000/50000 (80%)]\tLoss: 2.810602\n",
    "\n",
    "Test set: Average loss: 3.4225, Accuracy: 1972/10000 (20%)\n",
    "\n",
    "Train Epoch: 17 [0/50000 (0%)]\tLoss: 4.025714\n",
    "Train Epoch: 17 [40000/50000 (80%)]\tLoss: 2.831839\n",
    "\n",
    "Test set: Average loss: 3.3644, Accuracy: 2077/10000 (21%)\n",
    "\n",
    "Train Epoch: 18 [0/50000 (0%)]\tLoss: 2.951268\n",
    "Train Epoch: 18 [40000/50000 (80%)]\tLoss: 3.556488\n",
    "\n",
    "Test set: Average loss: 3.3326, Accuracy: 2135/10000 (21%)\n",
    "\n",
    "Train Epoch: 19 [0/50000 (0%)]\tLoss: 2.837605\n",
    "Train Epoch: 19 [40000/50000 (80%)]\tLoss: 2.981775\n",
    "\n",
    "Test set: Average loss: 3.3058, Accuracy: 2175/10000 (22%)\n",
    "\n",
    "Train Epoch: 20 [0/50000 (0%)]\tLoss: 3.772324\n",
    "Train Epoch: 20 [40000/50000 (80%)]\tLoss: 3.295967\n",
    "\n",
    "Test set: Average loss: 3.3042, Accuracy: 2178/10000 (22%)\n",
    "\n",
    "Train Epoch: 21 [0/50000 (0%)]\tLoss: 3.686811\n",
    "Train Epoch: 21 [40000/50000 (80%)]\tLoss: 2.765081\n",
    "\n",
    "Test set: Average loss: 3.2492, Accuracy: 2291/10000 (23%)\n",
    "\n",
    "Train Epoch: 22 [0/50000 (0%)]\tLoss: 3.459053\n",
    "Train Epoch: 22 [40000/50000 (80%)]\tLoss: 2.574803\n",
    "\n",
    "Test set: Average loss: 3.2196, Accuracy: 2356/10000 (24%)\n",
    "\n",
    "Train Epoch: 23 [0/50000 (0%)]\tLoss: 3.288209\n",
    "Train Epoch: 23 [40000/50000 (80%)]\tLoss: 2.942970\n",
    "\n",
    "Test set: Average loss: 3.1960, Accuracy: 2394/10000 (24%)\n",
    "\n",
    "Train Epoch: 24 [0/50000 (0%)]\tLoss: 3.508090\n",
    "Train Epoch: 24 [40000/50000 (80%)]\tLoss: 2.875761\n",
    "\n",
    "Test set: Average loss: 3.1837, Accuracy: 2442/10000 (24%)\n",
    "\n",
    "Train Epoch: 25 [0/50000 (0%)]\tLoss: 3.097573\n",
    "Train Epoch: 25 [40000/50000 (80%)]\tLoss: 2.783886\n",
    "\n",
    "Test set: Average loss: 3.1584, Accuracy: 2482/10000 (25%)\n",
    "\n",
    "Train Epoch: 26 [0/50000 (0%)]\tLoss: 3.077751\n",
    "Train Epoch: 26 [40000/50000 (80%)]\tLoss: 2.863167\n",
    "\n",
    "Test set: Average loss: 3.1382, Accuracy: 2532/10000 (25%)\n",
    "\n",
    "Train Epoch: 27 [0/50000 (0%)]\tLoss: 3.157701\n",
    "Train Epoch: 27 [40000/50000 (80%)]\tLoss: 3.405468\n",
    "\n",
    "Test set: Average loss: 3.1314, Accuracy: 2521/10000 (25%)\n",
    "\n",
    "Train Epoch: 28 [0/50000 (0%)]\tLoss: 3.381003\n",
    "Train Epoch: 28 [40000/50000 (80%)]\tLoss: 2.636311\n",
    "\n",
    "Test set: Average loss: 3.1026, Accuracy: 2578/10000 (26%)\n",
    "\n",
    "Train Epoch: 29 [0/50000 (0%)]\tLoss: 2.735946\n",
    "Train Epoch: 29 [40000/50000 (80%)]\tLoss: 2.728709\n",
    "\n",
    "Test set: Average loss: 3.0930, Accuracy: 2573/10000 (26%)\n",
    "\n",
    "Train Epoch: 30 [0/50000 (0%)]\tLoss: 3.060843\n",
    "Train Epoch: 30 [40000/50000 (80%)]\tLoss: 2.819065\n",
    "\n",
    "Test set: Average loss: 3.0722, Accuracy: 2642/10000 (26%)\n",
    "\n",
    "Train Epoch: 31 [0/50000 (0%)]\tLoss: 2.701449\n",
    "Train Epoch: 31 [40000/50000 (80%)]\tLoss: 2.802288\n",
    "\n",
    "Test set: Average loss: 3.0580, Accuracy: 2698/10000 (27%)\n",
    "\n",
    "Train Epoch: 32 [0/50000 (0%)]\tLoss: 2.812822\n",
    "Train Epoch: 32 [40000/50000 (80%)]\tLoss: 2.769371\n",
    "\n",
    "Test set: Average loss: 3.0651, Accuracy: 2667/10000 (27%)\n",
    "\n",
    "Train Epoch: 33 [0/50000 (0%)]\tLoss: 2.965749\n",
    "Train Epoch: 33 [40000/50000 (80%)]\tLoss: 2.678886\n",
    "\n",
    "Test set: Average loss: 3.0527, Accuracy: 2725/10000 (27%)\n",
    "\n",
    "Train Epoch: 34 [0/50000 (0%)]\tLoss: 2.349275\n",
    "Train Epoch: 34 [40000/50000 (80%)]\tLoss: 3.397193\n",
    "\n",
    "Test set: Average loss: 3.0369, Accuracy: 2759/10000 (28%)\n",
    "\n",
    "Train Epoch: 35 [0/50000 (0%)]\tLoss: 2.528225\n",
    "Train Epoch: 35 [40000/50000 (80%)]\tLoss: 2.322527\n",
    "\n",
    "Test set: Average loss: 3.0389, Accuracy: 2731/10000 (27%)\n",
    "\n",
    "Train Epoch: 36 [0/50000 (0%)]\tLoss: 2.765345\n",
    "Train Epoch: 36 [40000/50000 (80%)]\tLoss: 2.300882\n",
    "\n",
    "Test set: Average loss: 3.0304, Accuracy: 2732/10000 (27%)\n",
    "\n",
    "Train Epoch: 37 [0/50000 (0%)]\tLoss: 2.536705\n",
    "Train Epoch: 37 [40000/50000 (80%)]\tLoss: 2.632447\n",
    "\n",
    "Test set: Average loss: 3.0170, Accuracy: 2782/10000 (28%)\n",
    "\n",
    "Train Epoch: 38 [0/50000 (0%)]\tLoss: 2.408066\n",
    "Train Epoch: 38 [40000/50000 (80%)]\tLoss: 2.649137\n",
    "\n",
    "Test set: Average loss: 3.0178, Accuracy: 2783/10000 (28%)\n",
    "\n",
    "Train Epoch: 39 [0/50000 (0%)]\tLoss: 2.461593\n",
    "Train Epoch: 39 [40000/50000 (80%)]\tLoss: 2.682473\n",
    "\n",
    "Test set: Average loss: 3.0040, Accuracy: 2799/10000 (28%)\n",
    "\n",
    "Train Epoch: 40 [0/50000 (0%)]\tLoss: 2.265219\n",
    "Train Epoch: 40 [40000/50000 (80%)]\tLoss: 2.050575\n",
    "\n",
    "Test set: Average loss: 2.9966, Accuracy: 2801/10000 (28%)\n",
    "\n",
    "Train Epoch: 41 [0/50000 (0%)]\tLoss: 2.827886\n",
    "Train Epoch: 41 [40000/50000 (80%)]\tLoss: 2.499863\n",
    "\n",
    "Test set: Average loss: 2.9927, Accuracy: 2827/10000 (28%)\n",
    "\n",
    "Train Epoch: 42 [0/50000 (0%)]\tLoss: 2.893034\n",
    "Train Epoch: 42 [40000/50000 (80%)]\tLoss: 2.854383\n",
    "\n",
    "Test set: Average loss: 2.9855, Accuracy: 2853/10000 (29%)\n",
    "\n",
    "Train Epoch: 43 [0/50000 (0%)]\tLoss: 3.673101\n",
    "Train Epoch: 43 [40000/50000 (80%)]\tLoss: 2.847880\n",
    "\n",
    "Test set: Average loss: 3.0089, Accuracy: 2800/10000 (28%)\n",
    "\n",
    "Train Epoch: 44 [0/50000 (0%)]\tLoss: 2.480524\n",
    "Train Epoch: 44 [40000/50000 (80%)]\tLoss: 2.260675\n",
    "\n",
    "Test set: Average loss: 2.9796, Accuracy: 2852/10000 (29%)\n",
    "\n",
    "Train Epoch: 45 [0/50000 (0%)]\tLoss: 3.029518\n",
    "Train Epoch: 45 [40000/50000 (80%)]\tLoss: 3.397951\n",
    "\n",
    "Test set: Average loss: 2.9897, Accuracy: 2827/10000 (28%)\n",
    "\n",
    "Train Epoch: 46 [0/50000 (0%)]\tLoss: 2.133708\n",
    "Train Epoch: 46 [40000/50000 (80%)]\tLoss: 2.689017\n",
    "\n",
    "Test set: Average loss: 2.9726, Accuracy: 2873/10000 (29%)\n",
    "\n",
    "Train Epoch: 47 [0/50000 (0%)]\tLoss: 2.948929\n",
    "Train Epoch: 47 [40000/50000 (80%)]\tLoss: 2.023050\n",
    "\n",
    "Test set: Average loss: 2.9661, Accuracy: 2903/10000 (29%)\n",
    "\n",
    "Train Epoch: 48 [0/50000 (0%)]\tLoss: 2.379103\n",
    "Train Epoch: 48 [40000/50000 (80%)]\tLoss: 2.243538\n",
    "\n",
    "Test set: Average loss: 2.9785, Accuracy: 2904/10000 (29%)\n",
    "\n",
    "Train Epoch: 49 [0/50000 (0%)]\tLoss: 2.108592\n",
    "Train Epoch: 49 [40000/50000 (80%)]\tLoss: 2.367362\n",
    "\n",
    "Test set: Average loss: 2.9703, Accuracy: 2857/10000 (29%)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# loss=[]\n",
    "# acc=[]\n",
    "# loss2=[]\n",
    "#\n",
    "# for i in txt.split('\\n'):\n",
    "#      if len(i)>0:\n",
    "#         if '40000/50000 ' in i:\n",
    "#             loss.append(float(i.split()[-1].strip()))\n",
    "#         if 'Test' in i:\n",
    "#             loss2.append(float(i.split()[4].strip().replace(\",\", \"\")))\n",
    "#             acc.append(float(i.split()[-2].split('/')[0])/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib as mpl\n",
    "# from matplotlib import pyplot as plt\n",
    "#\n",
    "# mpl.use('nbAgg')\n",
    "# mpl.style.use('seaborn-darkgrid')\n",
    "# import numpy as np\n",
    "# def plotP(test_loss, train_loss, train_acc_list, test_acc_list):\n",
    "#     plt.figure(figsize=(6, 8))\n",
    "#     x = np.linspace(0,  len(train_loss))\n",
    "#     y = np.linspace(0, len(test_acc_list))\n",
    "#     plt.subplot(2, 1, 1)\n",
    "#     plt.plot(x, train_loss, label=\"train_loss\")\n",
    "#     plt.plot(x, test_loss, label=\"test_loss\")\n",
    "#\n",
    "#     plt.xlabel(\"epoch\")\n",
    "#     plt.ylabel(\"loss\")\n",
    "#     plt.legend()\n",
    "#     plt.subplot(2, 1, 2)\n",
    "#     plt.plot(y, test_acc_list, label=\"test_acc\")\n",
    "#     plt.xlabel(\"epoch\")\n",
    "#     plt.ylabel(\"acc\")\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "# plotP(loss2, loss, [], acc)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "name": "conda-env-pysyft-py",
   "language": "python",
   "display_name": "Python [conda env:pysyft]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "785px",
    "left": "120px",
    "top": "110.525px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}