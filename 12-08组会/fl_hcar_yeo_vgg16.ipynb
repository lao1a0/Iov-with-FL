{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ce5904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env py\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "import syft as sy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import xlwt\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db7dbec",
   "metadata": {},
   "source": [
    "#  定义超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0406b145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "现在训练的是：yeo_alexnet_lr0.01_epoch50\n",
      "使用的训练集：/home/raoxy/data/train_yeo\n",
      "使用的测试集：/home/raoxy/data/test_yeo\n"
     ]
    }
   ],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 32\n",
    "        self.epochs = 50\n",
    "        self.lr = 0.02\n",
    "        self.num_class = 5\n",
    "        self.save_name = 'yeo_alexnet_lr0.01_epoch50'\n",
    "        self.data_train = '/home/raoxy/data/train_yeo'\n",
    "        self.data_test = '/home/raoxy/data/test_yeo'\n",
    "        self.model_name = '/home/raoxy/model/vgg16-397923af.pth'\n",
    "        self.flag = True\n",
    "\n",
    "args = Arguments()\n",
    "print(\"现在训练的是：{}\".format(args.save_name))\n",
    "print(\"使用的训练集：{}\".format(args.data_train))\n",
    "print(\"使用的测试集：{}\".format(args.data_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46e2556",
   "metadata": {},
   "source": [
    "#  定义参与者"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b441d8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "\n",
    "federated_train_loader = sy.FederatedDataLoader(\n",
    "    torchvision.datasets.ImageFolder(root=args.data_train,\n",
    "                                     transform=torchvision.transforms.ToTensor()).federate((bob, alice)),\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "federated_test_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(root=args.data_test,\n",
    "                                     transform=torchvision.transforms.ToTensor()),\n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d276b668",
   "metadata": {},
   "source": [
    "# 定义训练函数和测试函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aa51579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, federated_train_loader, optimizer):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    sample_num = 0\n",
    "    total_loss = 0\n",
    "    train_batch_num = len(federated_train_loader)\n",
    "\n",
    "    for idx, (data, target) in enumerate(federated_train_loader):\n",
    "        model.send(data.location)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.get().data\n",
    "        pred = output.argmax(1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().get()\n",
    "        sample_num += len(pred)\n",
    "        model.get()\n",
    "    return total_loss / train_batch_num, correct.cpu().item() / sample_num\n",
    "\n",
    "\n",
    "def test(model, device, federated_test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "    sample_num = 0\n",
    "    test_batch_num = len(federated_test_loader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(federated_test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            loss = F.cross_entropy(output, target.long())\n",
    "            total_loss += loss.data\n",
    "\n",
    "            pred = output.argmax(1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum()\n",
    "            sample_num += len(pred)\n",
    "\n",
    "    return total_loss.cpu() / test_batch_num, correct.cpu().item() / sample_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5808015a",
   "metadata": {},
   "source": [
    " # 定义训练模型\n",
    " \n",
    " ```\n",
    " wget https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "572e4dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "现在是在： cpu\n"
     ]
    }
   ],
   "source": [
    "def VGG_s(args):\n",
    "    from torchvision.models import vgg11, vgg13, vgg16, vgg19  # VGG系列\n",
    "    from collections import OrderedDict\n",
    "    pretrain_model = vgg16(pretrained=False)  # 导入了模型的框架\n",
    "    pretrain_model.classifier[6] = nn.Linear(pretrain_model.classifier[6].in_features, 5)  # 将全连接层改为自己想要的分类输出\n",
    "    model_dict = pretrain_model.state_dict()\n",
    "\n",
    "    pretrained_dict = torch.load(args.model_name)\n",
    "    pretrained_dict.pop('classifier.6.bias')\n",
    "    pretrained_dict.pop('classifier.6.weight')\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "\n",
    "    model_dict.update(pretrained_dict)  # 模型参数列表进行参数更新，加载参数\n",
    "    pretrain_model.load_state_dict(model_dict)\n",
    "    # 将满足条件的参数的 requires_grad 属性设置为False\n",
    "    for name, value in pretrain_model.named_parameters():\n",
    "        if (name != 'classifier.6.weight') and (name != 'classifier.6.bias'):\n",
    "            value.requires_grad = False\n",
    "            \n",
    "    upsample = nn.Upsample(size=[224,224], mode='bilinear', align_corners=True)\n",
    "    new_model = nn.Sequential(OrderedDict([\n",
    "                      ('laolao', upsample),\n",
    "                      ('features', pretrain_model.features),\n",
    "                      ('avgpool',pretrain_model.avgpool),\n",
    "                      ('classifier', nn.Sequential(\n",
    "                                               nn.Flatten(start_dim=1, end_dim=3),\n",
    "                                                pretrain_model.classifier[0],\n",
    "                                                pretrain_model.classifier[1],\n",
    "                                                pretrain_model.classifier[2],\n",
    "                                                pretrain_model.classifier[3],\n",
    "                                                pretrain_model.classifier[4],\n",
    "                                                pretrain_model.classifier[5],\n",
    "                                                pretrain_model.classifier[6]\n",
    "                                                 ))\n",
    "    ])) # 创建一个新的模型\n",
    "    params_conv = filter(lambda p: p.requires_grad, new_model.parameters()) # 要更新的参数在parms_conv当中\n",
    "    return new_model, params_conv\n",
    "\n",
    "model, params_conv = VGG_s(args)\n",
    "print('现在是在：',device)\n",
    "optims = optim.SGD(params_conv, lr=args.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269aea8c",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25224405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train_loss 0.015250,test_loss 1.367353,train_acc 0.997476,test_acc 0.598577,time cost 23661.311592\n",
      "epoch 2, train_loss 0.004166,test_loss 0.081814,train_acc 0.999279,test_acc 0.978081,time cost 23248.808673\n",
      "epoch 3, train_loss 0.001739,test_loss 0.016876,train_acc 0.999848,test_acc 0.994933,time cost 23078.047661\n"
     ]
    }
   ],
   "source": [
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "time_list = []\n",
    "timestart = time.perf_counter()\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    epochstart = time.perf_counter()  # 每一个epoch的开始时间\n",
    "    train_loss, train_acc = train(model, device, federated_train_loader, optims)\n",
    "    elapsed = (time.perf_counter() - epochstart)  # 每一个epoch的结束时间 记录训练的耗时\n",
    "    test_loss, test_acc = test(model, device, federated_test_loader)\n",
    "    # 保存各个指际\n",
    "    train_loss_list.append(train_loss.cpu())\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_loss_list.append(test_loss.cpu())\n",
    "    test_acc_list.append(test_acc)\n",
    "    time_list.append(elapsed)\n",
    "    print('epoch %d, train_loss %.6f,test_loss %.6f,train_acc %.6f,test_acc %.6f,time cost %.6f' % (\n",
    "        epoch, train_loss, test_loss,\n",
    "        train_acc, test_acc, elapsed))\n",
    "\n",
    "# 训练数据保存\n",
    "torch.save(model.state_dict(), \"/home/raoxy/model/{}.pt\".format(args.save_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89cc1ce",
   "metadata": {},
   "source": [
    "# 训练数据保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4190d1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _change(a):\n",
    "    b = []\n",
    "    for i in a:\n",
    "        b.append(float(i))\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e504498",
   "metadata": {},
   "source": [
    "## 创建workbook和sheet对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573bb8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "file_name = '/home/raoxy/file/{}_{}.xlsx'.format(args.save_name,datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f535191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建workbook和sheet对象\n",
    "workboot = xlwt.Workbook(encoding='utf-8')\n",
    "worksheet = workboot.add_sheet('result')  # 设置工作表的名字\n",
    "# 写入Excel标题\n",
    "row0 = [\"Train loss\", \"Train acc\", \"Test loss\", 'Test acc', 'Time']\n",
    "for i in range(len(row0)):\n",
    "    worksheet.write(0, i, row0[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da45fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_list = _change(test_loss_list)\n",
    "train_loss_list = _change(train_loss_list)\n",
    "train_acc_list = _change(train_acc_list)\n",
    "test_acc_list = _change(test_acc_list)\n",
    "time_list = _change(time_list)\n",
    "\n",
    "length = len(test_loss_list)\n",
    "\n",
    "for i in range(1, length + 1):\n",
    "    worksheet.write(i, 0, train_loss_list[i - 1])\n",
    "    worksheet.write(i, 1, train_acc_list[i - 1])\n",
    "    worksheet.write(i, 2, test_loss_list[i - 1])\n",
    "    worksheet.write(i, 3, test_acc_list[i - 1])\n",
    "    worksheet.write(i, 4, time_list[i - 1])\n",
    "workboot.save(file_name)\n",
    "print(\"保存文件：\",file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524a0b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plotP(test_loss, train_loss, train_acc_list, test_acc_list):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    x = np.linspace(0, len(train_loss), len(train_loss))\n",
    "    y = np.linspace(0, len(train_acc_list), len(train_acc_list))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(x, train_loss, label=\"train_loss\")\n",
    "    plt.plot(x, test_loss, label=\"test_loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend()\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(y, train_acc_list, label=\"train_acc\")\n",
    "    plt.plot(y, test_acc_list, label=\"test_acc\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"acc\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plotP(test_loss_list, train_loss_list, train_acc_list, test_acc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6990768c",
   "metadata": {},
   "source": [
    "# 结果分析\n",
    "\n",
    "## 模型预测\n",
    "\n",
    "### 生成预测的配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8037ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_root='/home/raoxy/data/verify_yeo/'\n",
    "true_label_txt='/home/raoxy/file/true_label_vgg16_yeo.txt'\n",
    "\n",
    "def Create_data_dir_with_true_label(_root, save_name):\n",
    "    ''':cvar保存每一张图片的地址+对应的正确的标签'''\n",
    "    _list = []\n",
    "    for a, b, c in os.walk(_root):\n",
    "        for i in range(len(c)):\n",
    "            _list.append(os.path.join(a, c[i]))\n",
    "    with open(save_name, 'w', encoding='UTF-8') as f:\n",
    "        for _img in _list:\n",
    "            f.write(_img + '\\t' + str(_img.split('/')[-2]) + '\\n')\n",
    "    print(\"生成文件成功：\",save_name)\n",
    "\n",
    "Create_data_dir_with_true_label(verify_root, true_label_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11268c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_root='/home/raoxy/data/verify_yeo/'\n",
    "predicted_label_txt='/home/raoxy/file/predicted_label_vgg16_yeo.txt'\n",
    "\n",
    "def Create_data_dir_with_no_label(_root, save_name):\n",
    "    _list = []\n",
    "    for a, b, c in os.walk(_root):\n",
    "        for i in range(len(c)):\n",
    "            _list.append(os.path.join(a, c[i]))\n",
    "    # print(_list)\n",
    "    with open(save_name, 'w', encoding='UTF-8') as f:\n",
    "        for _img in _list:\n",
    "            f.write(_img + '\\t' + \"0\" + '\\n')\n",
    "    print(\"生成文件成功：\",save_name)\n",
    "\n",
    "Create_data_dir_with_no_label(verify_root, predicted_label_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeb22f0",
   "metadata": {},
   "source": [
    "### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e784262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg16  # VGG系列\n",
    "model = vgg16(pretrained=False, num_classes=5)  # 导入了模型的框架\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "model_loc = args.model_weight\n",
    "model_dict = torch.load(model_loc)\n",
    "model.load_state_dict(model_dict)\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7de79d",
   "metadata": {},
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bb5919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_label_txt='/home/raoxy/file/true_label_cnn_yeo.txt'\n",
    "\n",
    "def eval(dataloader, model):\n",
    "    label_list = []\n",
    "    likelihood_list = []\n",
    "    pred_list = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 加载数据加载器，得到里面的X（图片数据）和y(真实标签）\n",
    "        for idx, (X, y) in enumerate(dataloader):\n",
    "            # 将图片传入到模型当中就，得到预测的值pred\n",
    "            pred = model(X)\n",
    "            pred_softmax = torch.softmax(pred, 1).cpu().numpy()\n",
    "            # 获取可能性最大的标签\n",
    "            label = torch.softmax(pred, 1).cpu().numpy().argmax()\n",
    "            label_list.append(label)\n",
    "            # 获取可能性最大的值（即概率）\n",
    "            likelihood = torch.softmax(pred, 1).cpu().numpy().max()\n",
    "            likelihood_list.append(likelihood)\n",
    "            pred_list.append(pred_softmax.tolist()[0])\n",
    "\n",
    "        return label_list, likelihood_list, pred_list\n",
    "\n",
    "valid_data = LoadData(true_label_txt  , train_flag=False)\n",
    "_dataloader = DataLoader(dataset=valid_data, num_workers=4, pin_memory=True, batch_size=1)\n",
    "\n",
    "label_list, likelihood_list, pred = eval(_dataloader, model)\n",
    "print(label_list)\n",
    "print(likelihood_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8998feda",
   "metadata": {},
   "source": [
    "### 将输出保存到exel中，方便后续分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4267ffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = 'yeo_vgg16_lr0.01_epoch50'\n",
    "label_names = ['R', 'RPM', 'gear', 'DoS', 'Fuzzy']\n",
    "df = pd.DataFrame(data=pred, columns=label_names)\n",
    "df.to_csv('/home/raoxy/file/{}.csv'.format(save_name), encoding='utf-8', index=False)\n",
    "print('执行完毕，生成文件：/home/raoxy/file/{}.csv'.format(save_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1632a7e",
   "metadata": {},
   "source": [
    "##  绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f524a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data = pd.read_csv(true_label_txt, sep=\"\\t\", names=[\"loc\", \"type\"])\n",
    "true_label = [i for i in target_data[\"type\"]]\n",
    "true_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d919353",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = 'yeo_vgg16_lr0.01_epoch50'\n",
    "\n",
    "predict_loc ='/home/raoxy/file/{}.csv'.format(save_name)    # 3.ModelEvaluate.py生成的文件\n",
    "predict_data = pd.read_csv(predict_loc)#,index_col=0)\n",
    "predict_label = predict_data.to_numpy().argmax(axis=1)\n",
    "predict_score = predict_data.to_numpy().max(axis=1)\n",
    "# predict_score = predict_data.to_numpy().max(axis=1)\n",
    "# # 精度，准确率， 预测正确的占所有样本种的比例\n",
    "print(len(predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81adeefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score  # pip install scikit-learn\n",
    "accuracy = accuracy_score(true_label, predict_label)\n",
    "print(\"精度: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951d1301",
   "metadata": {},
   "source": [
    "## 查准率P（准确率），precision(查准率)=TP/(TP+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b198ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(true_label, predict_label, labels=None, pos_label=1, average='macro') # 'micro', 'macro', 'weighted'\n",
    "print(\"查准率P: \",precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32b394e",
   "metadata": {},
   "source": [
    "## 查全率R（召回率），原本为对的，预测正确的比例；recall(查全率)=TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742a043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(true_label, predict_label, average='macro') # 'micro', 'macro', 'weighted'\n",
    "print(\"召回率: \",recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca66913",
   "metadata": {},
   "source": [
    "## F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231ad650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(true_label, predict_label, average='macro')     # 'micro', 'macro', 'weighted'\n",
    "print(\"F1 Score: \",f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179b567d",
   "metadata": {},
   "source": [
    "## 混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7e78f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_fig_title='cnn_yeo'\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "label_names = ['R', 'RPM',  'gear', 'DoS', 'Fuzzy']\n",
    "confusion = confusion_matrix(true_label, predict_label, labels=[i for i in range(len(label_names))])\n",
    "plt.matshow(confusion, cmap=plt.cm.Oranges)   # Greens, Blues, Oranges, Reds\n",
    "plt.colorbar()\n",
    "for i in range(len(confusion)):\n",
    "    for j in range(len(confusion)):\n",
    "        plt.annotate(confusion[j,i], xy=(i, j), horizontalalignment='center', verticalalignment='center')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.xticks(range(len(label_names)), label_names)\n",
    "plt.yticks(range(len(label_names)), label_names)\n",
    "# plt.title(\"{} Confusion Matrix\".format(_fig_title))\n",
    "plt.show()\n",
    "plt.savefig('/home/raoxy/img/{}_Confusion_Matrix.png'.format(_fig_title),bbox_inches=\"tight\")\n",
    "print('执行完毕，生成文件：/home/raoxy/img/{}_Confusion_Matrix.png'.format(_fig_title))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d65ff32",
   "metadata": {},
   "source": [
    "## ROC曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706b86d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,auc\n",
    "\n",
    "n_classes = len(label_names)\n",
    "# binarize_predict = label_binarize(predict_label, classes=[i for i in range(n_classes)])\n",
    "binarize_predict = label_binarize(true_label, classes=[i for i in range(n_classes)])\n",
    "# 读取预测结果\n",
    "predict_score = predict_data.to_numpy()\n",
    "# 计算每一类的ROC\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(binarize_predict[:,i], [socre_i[i] for socre_i in predict_score])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "print(\"roc_auc = \",roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ee50c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "# Plot all ROC curves\n",
    "lw = 2\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45789b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "_fig_title='vgg16_yeo'\n",
    "\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], lw=lw, label='ROC curve of {0} (area = {1:0.2f})'.format(label_names[i], roc_auc[i]))\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "\n",
    "plt.title('{} Multi-class receiver operating characteristic'.format(_fig_title))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "# plt.savefig('../img/{}_roc_fig.png'.format(args._fig_title),bbox_inches=\"tight\")\n",
    "# print('执行完毕生成文件：../img/{}_roc_fig.png'.format(_fig_title))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:pysyft]",
   "language": "python",
   "name": "conda-env-pysyft-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "164.562px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
