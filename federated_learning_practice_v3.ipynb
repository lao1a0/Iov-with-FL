{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning Practice on MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "import copy\n",
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a couple workers\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "secure_worker_a = sy.VirtualWorker(hook, id=\"secure_worker_a\")\n",
    "secure_worker_b = sy.VirtualWorker(hook, id=\"secure_worker_b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "train_transforms = transforms.Compose([#transforms.RandomRotation(30),\n",
    "                                       # transforms.RandomResizedCrop(224),\n",
    "                                       # transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.5,], [0.5,])]) # mean, std\n",
    " \n",
    "\n",
    "test_transforms = transforms.Compose([#transforms.Resize(255),\n",
    "                                      #transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.5,], [0.5,])]) # mean, std\n",
    "\n",
    "\n",
    "# choose the training and test datasets\n",
    "\n",
    "federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
    "    datasets.MNIST('/home/zhaojia-raoxy/data', train=True, download=True,\n",
    "                   transform=train_transforms)\n",
    "    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "    batch_size=20, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "federated_test_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
    "    datasets.MNIST('/home/zhaojia-raoxy/data', train=False, download=True,\n",
    "                   transform=test_transforms)\n",
    "    .federate((secure_worker_a, secure_worker_b)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "    batch_size=20, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型\n",
    "## Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, channel=3, hideen=768, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        act = nn.Sigmoid\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channel, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=1),\n",
    "            act(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hideen, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.03) # TODO momentum is not supported at the moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN(nn.Module):\n",
    "#     def __init__(self, num_class):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.block1 = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5),\n",
    "#             nn.ReLU(),\n",
    "#             nn.AdaptiveAvgPool2d(5),\n",
    "#             nn.Dropout(p=0.5)\n",
    "\n",
    "#         )\n",
    "#         self.block2 = nn.Sequential(\n",
    "#             nn.Conv2d(64, 32, 5, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2),\n",
    "#         )\n",
    "#         self.block3 = nn.Sequential(\n",
    "#             nn.Linear(32, num_class),\n",
    "#             nn.LogSoftmax(dim=1)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.block1(x)\n",
    "#         x = self.block2(x)\n",
    "#         x = x.view(x.shape[0], -1)  # torch.Size([128, 32])\n",
    "#         x = self.block3(x)\n",
    "#         return x\n",
    "\n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self, num_class=10):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.block1 = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2),\n",
    "#             nn.Dropout(p=0.5)\n",
    "\n",
    "#         )\n",
    "#         self.block2 = nn.Sequential(\n",
    "#             nn.Conv2d(64, 32, 3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2),\n",
    "#         )\n",
    "#         self.block3 = nn.Sequential(\n",
    "#             nn.Linear(32, num_class),\n",
    "#             nn.LogSoftmax(dim=1)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.block1(x)\n",
    "#         x = self.block2(x)\n",
    "#         x = x.view(x.shape[0], -1)  # torch.Size([128, 32])\n",
    "#         x = self.block3(x)\n",
    "#         return x\n",
    "    \n",
    "# model = CNN(10).to(device)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.03) # TODO momentum is not supported at the moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = '/home/zhaojia-raoxy/model/resnet18-5c106cde.pth'\n",
    "\n",
    "# def ResNet_s(model_name):\n",
    "#     ''':cvar\n",
    "#     返回修改好的模型，和冻结好的参数\n",
    "#     '''\n",
    "#     from torchvision.models import resnet18\n",
    "#     pretrain_model = resnet18(pretrained=False)\n",
    "#     pretrain_model.fc = nn.Linear(pretrain_model.fc.in_features, 10)  # 将全连接层改为自己想要的分类输出\n",
    "#     pretrained_dict = torch.load(model_name)\n",
    "\n",
    "#     pretrained_dict.pop('fc.weight')\n",
    "#     pretrained_dict.pop('fc.bias')\n",
    "\n",
    "#     model_dict = pretrain_model.state_dict()\n",
    "#     pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "\n",
    "#     model_dict.update(pretrained_dict)  # 模型参数列表进行参数更新，加载参数\n",
    "#     pretrain_model.load_state_dict(model_dict)  # 将满足条件的参数的 requires_grad 属性设置为False\n",
    "\n",
    "# #     for name, value in pretrain_model.named_parameters():\n",
    "# #         if (name != 'fc.weight') and (name != 'fc.bias'):\n",
    "# #             value.requires_grad = False\n",
    "#     params_conv = filter(lambda p: p.requires_grad, pretrain_model.parameters())  # 要更新的参数在parms_conv当中\n",
    "#     return pretrain_model, params_conv\n",
    "\n",
    "# model, params_conv = ResNet_s(model_name)\n",
    "# model=model.to(device)\n",
    "# optimizer = optim.SGD(params_conv, lr=0.03) # TODO momentum is not supported at the moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, channel=3, hideen=768, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        act = nn.Sigmoid\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channel, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=1),\n",
    "            act(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hideen, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "model = LeNet(channel=1, hideen=hidden, num_classes=10).to(device)\n",
    "optimizer = optim.SGD(params_conv, lr=0.03) # TODO momentum is not supported at the moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, federated_train_loader, optimizer, epoch, batch_size):\n",
    "    model.train()\n",
    "   \n",
    "    for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
    "        model.send(data.location) # <-- NEW: send the model to the right location\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target.long())\n",
    "#         loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.get() # <-- NEW: get the model back\n",
    "        \n",
    "        if batch_idx % 2000 == 0:\n",
    "            loss = loss.get() # <-- NEW: get the loss\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * batch_size, len(federated_train_loader) * batch_size,\n",
    "                100. * batch_idx / len(federated_train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, federated_test_loader, batch_size): \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in federated_test_loader:\n",
    "            model.send(data.location) # <-- NEW: send the model in virtual workers to Trusted Aggregator\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target, reduction='sum')\n",
    "            model.get()\n",
    "            test_loss += loss.get() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().get()\n",
    "    test_loss /= len(federated_test_loader)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(federated_test_loader) * batch_size,\n",
    "        100. * correct / len(federated_test_loader) / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(50):\n",
    "    train(model, device, federated_train_loader, optimizer, epoch, batch_size=20)\n",
    "    test(model, device, federated_test_loader, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name='ResNet18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-d528fd0283d9>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# 保存模型的权重\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"/home/zhaojia-raoxy/model/out/{}.pt\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msave_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"保存文件：\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"/home/zhaojia-raoxy/model/out/{}.pt\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msave_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# 保存模型的权重\n",
    "torch.save(model.state_dict(), \"/home/zhaojia-raoxy/model/out/{}.pt\".format(save_name))\n",
    "print(\"保存文件：\",\"/home/zhaojia-raoxy/model/out/{}.pt\".format(save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存整个模型\n",
    "torch.save(model, \"/home/zhaojia-raoxy/model/out/{}.h5\".format(save_name))\n",
    "print(\"保存文件：\",\"/home/zhaojia-raoxy/model/out/{}.h5\".format(save_name))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:pysyft]",
   "language": "python",
   "name": "conda-env-pysyft-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "785px",
    "left": "47px",
    "top": "355px",
    "width": "179.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}